%-----------------------------------------------------------------------------------------------------------------------------
% \chapter{Machine Learning-Based Intrusion Detection System Approaches}
% This section will provide an overview of various approaches that have been developed for intrusion detection.
% Many works are being carried out in this context to find the best parameters and results for intrusion detection in various environments, and this survey will examine some of the most recent studies. The section will conclude with a summary table of the reviewed approaches.\\
% ============================== ARTICLE 1 =====================================
\section{Towards Realizing the Vision of Precision Medicine: AI-Based Prediction of Clinical Drug Response}
\textbf{Article Reference:} \cite{article_1}

\subsection*{Overview}
This study uses machine learning to predict patient response to the epilepsy drug brivaracetam using integrated clinical and genomic data. The resulting model demonstrated strong performance (AUC: 0.76 training, 0.75 validation) and identified specific biomarkers associated with poor response. The research underscores the potential of ML models to support precision medicine and optimize clinical trials by targeting likely responders. This study highlights the potential of AI to personalize treatment strategies in epilepsy by predicting drug response, a key aspect of personalized medicine.

\subsection*{Dataset}
\begin{itemize}
    \item \textbf{Discovery dataset:} 235 adult patients from a phase III clinical trial (NCT01261325).
    \item \textbf{External validation dataset:} 47 patients from an independent trial (NCT00490035).
\end{itemize}

\subsection*{Data Processing}
Clinical data included demographic and seizure-related information. Whole Genome Sequencing (WGS) data ($\sim$20 million variants) was filtered down to 40 features through knowledge-driven extraction, focusing on epilepsy-related genes and drug mechanism (e.g., SV2A gene, eQTLs). Genetic features included mutational load scores, polygenic risk scores, and structural variant descriptors.

\subsection*{ML Approach}
Multiple ML models were evaluated: sparse multi-block PLS-DA, multimodal neural networks, elastic net, gradient-boosted decision trees (GBDT), and stacked classifiers. The best performance was achieved using a GBDT model integrating all data types. GBDT models are well-suited for handling the complex interactions between clinical and genetic features, which is crucial for personalized drug response prediction. However, the inherent complexity of GBDT models can make it challenging to interpret the specific contributions of individual features, a limitation that future explainable AI (XAI) techniques could address.

\subsection*{Results}
\begin{itemize}
    \item AUC (training): 0.76
    \item AUC (validation): 0.75
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item Addressing high dimensionality and sparsity of genomic data. This is a common challenge in personalized medicine research, as genomic data often has many variables but few samples.
    \item Integrating additional data types (e.g., EEG, imaging) to improve model performance. Multimodal data integration is essential for a holistic view of the patient but increases complexity.
    \item Generalizing models to other anti-epileptic drugs. This is crucial for wider clinical applicability in personalized epilepsy treatment.
    \item Collaborating with regulatory bodies for clinical adoption. AI-driven personalized medicine tools require rigorous validation and regulatory approval for safe and effective use.
    \item Increasing dataset size to enhance model performance (targeting $\sim$350 patients for AUC = 0.9). Larger datasets are vital for building robust and generalizable predictive models in personalized healthcare.
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item The sample size, while sufficient for the study, could be larger to further enhance model performance and generalizability. 
    \item The complexity of the GBDT model, while providing good predictive power, makes it difficult to interpret the specific contributions of individual features.
    
\end{itemize}

% ============================== ARTICLE 2 =====================================
\section{Diabetes Prediction Using Machine Learning and Explainable AI Techniques}
\textbf{Article Reference:} \cite{article_2}

\subsection*{Overview}
This study proposes an automated diabetes prediction system using ML and explainable AI. The system combines the public Pima Indian dataset with a private dataset collected from female workers in a Bangladeshi textile factory. The system addresses data imbalance, missing values, and is deployed for real-time prediction via web and mobile applications. The development of non-invasive AI-driven tools for diabetes detection, as presented in this paper, contributes to personalized healthcare by enabling earlier and more accessible diagnosis.

\subsection*{Dataset}
\begin{itemize}
    \item \textbf{Pima Indian Dataset:} 768 records, 268 diabetes-positive; includes 8 features.
    \item \textbf{RTML Private Dataset:} 203 female employees; features similar to Pima dataset but lacks insulin values.
\end{itemize}

\subsection*{Data Processing}
\begin{itemize}
    \item Zero values in the merged dataset were replaced with corresponding mean values and the dataset was separated into training and test sets using the holdout validation technique.
    \item Mutual information was used to measure the interdependence of variables and feature importance.
    \item A semi-supervised approach using the extreme gradient boosting technique (XGB regressor) was used to predict the missing insulin feature of the RTML dataset.
\end{itemize}

\subsection*{ML Approach}
Various models were tested: decision trees, KNN, SVM, random forest, logistic regression, AdaBoost, XGBoost, bagging, and voting classifiers. Hyperparameters were tuned using GridSearchCV. The final model employed XGBoost with ADASYN for balancing. The choice of XGBoost is appropriate due to its effectiveness in handling complex datasets, but the lack of inherent explainability highlights the need for methods.

\subsection*{Results}
\begin{itemize}
    \item Accuracy: 81\%
    \item F1 Score: 0.81
    \item AUC: 0.84
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item Missing insulin values required imputation via semi-supervised learning. This introduces a degree of uncertainty into the model.
    \item Class imbalance necessitated oversampling (SMOTE, ADASYN). Oversampling techniques can sometimes lead to overfitting.
    \item Limited private dataset size may hinder generalizability. Larger, more diverse datasets would improve the robustness of the model.
\end{itemize}

\subsection*{Future Directions}
\begin{itemize}
    \item Expanding dataset size for better robustness.
    \item Integrating fuzzy logic and optimization for improved prediction.
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item The use of imputation for missing insulin values introduces some uncertainty.    
    \item The private dataset is relatively small, which may limit the model's generalizability.    
    
\end{itemize}

% ============================== ARTICLE 3 =====================================
\section{Integrating Machine Learning and Deep Learning Techniques for Advanced Alzheimer's Disease Detection through Gait Analysis}
\textbf{Article Reference:} \cite{article_3}

\subsection*{Overview}
The paper aims to enhance early detection of Alzheimer's Disease (AD) by leveraging gait analysis combined with advanced machine learning (ML) and deep learning (DL) techniques. Gait abnormalities, such as reduced stride length and irregular cadence, are identified as early biomarkers for cognitive decline associated with AD. The study emphasizes the need for non-invasive, scalable diagnostic tools. This research highlights the potential of AI-driven gait analysis to contribute to personalized AD management through early detection.

\subsection*{Dataset}
Data were collected using wearable sensors and motion capture systems in both clinical and real-world environments, providing high-resolution temporal and spatial gait metrics. The dataset includes gait features like stride length, cadence, swing time, and gait variability, with some data sourced from publicly available repositories like the UCI Machine Learning Repository.

\subsection*{Data Processing}
\begin{itemize}
    \item \textbf{Normalization:} Features were scaled between 0 and 1 to standardize the data, ensuring that features with larger ranges (e.g., stride length) did not dominate the model training.
    \item \textbf{Handling Missing Data:} Missing values were imputed using median substitution to maintain data integrity and reduce bias.
    \item \textbf{Class Imbalance:} The Synthetic Minority Over-sampling Technique (SMOTE) was applied to generate synthetic samples of the minority class (AD patients), addressing class imbalance issues.
    \item \textbf{Feature Selection:} Recursive Feature Elimination (RFE) was used to identify the most significant gait features—such as stride length, gait variability, and cadence—to improve model performance.
    \item \textbf{Correlation Analysis:} High correlations between key features (e.g., stride length and step length) validated their importance for prediction, informing feature selection.
\end{itemize}

\subsection*{ML Approach}
The study employed a hybrid deep learning model comprising Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) to classify individuals as healthy or at risk for AD. These models analyzed temporal-spatial gait features, capturing sequential patterns and irregularities. Traditional ML classifiers such as Random Forest and SVM were also evaluated for comparison. The use of a hybrid CNN-RNN model is a strength, as it leverages the capabilities of both CNNs for spatial feature extraction and RNNs for temporal sequence modeling, which is well-suited for gait analysis.

\subsection*{Results}
\begin{itemize}
    \item Hybrid CNN-RNN model accuracy: 93\%
    \item Precision: 92\% 
    \item Recall: 91\%
    \item F1-score: 91.5\%
    \item AUC-ROC: 95\%
    \item Traditional models: Random Forest (88\%) and SVM (86\%)
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item The reliance on controlled datasets, which may not fully reflect real-world variability, impacting model robustness.
    \item The complexity and interpretability of deep learning models, posing a barrier for clinical acceptance.
    \item The need for large, diverse datasets to ensure generalizability.
    \item Integration into clinical workflows and validation through real-world testing.
\end{itemize}

\subsection*{Future Directions}
\begin{itemize}
    \item Incorporating multimodal data sources, such as MRI, PET scans, vocal, and cognitive measures, to improve diagnostic precision.
    \item Expanding datasets to include diverse populations and environmental conditions, enhancing model robustness.
    \item Developing explainable AI frameworks to improve interpretability and clinician trust.
    \item Extending studies to include longitudinal gait data for monitoring disease progression and enabling earlier detection.
    \item Conducting clinical pilot studies and developing affordable wearable technologies for widespread, low-resource application.
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item The dataset may not fully represent the variability of real-world gait patterns.    
    \item Deep learning models are often considered "black boxes," which can hinder clinical acceptance.
\end{itemize}

% ============================== ARTICLE 4 =====================================
\section{Diabetes Detection Using Deep Learning Algorithms}
\textbf{Article Reference:} \cite{article_4}

\subsection*{Overview}
The authors developed a non-invasive method to detect diabetes using heart rate variability (HRV) signals derived from ECG data. They designed a deep learning architecture combining convolutional neural networks (CNN) and long short-term memory (LSTM) networks to automatically extract complex features from the HRV signals. These features were then classified using a support vector machine (SVM) with an RBF kernel. The approach achieved a high accuracy of 95.7\%, outperforming previous methods. This research demonstrates the potential of AI for non-invasive, personalized diabetes screening.

\subsection*{Dataset}
\begin{itemize}
    \item ECG recordings from 20 individuals (both diabetic and normal)
    \item Each participant provided a 10-minute ECG sample, from which heart rate time series data was derived
    \item Total datasets: 71 datasets for both groups, each containing 1000 samples
\end{itemize}

\subsection*{Data Processing}
\begin{itemize}
    \item Used Pan and Tompkins algorithm for QRS complex detection to extract heart rate intervals.
    \item Derived HRV signals directly from ECG without additional preprocessing.
    \item Input data fed into deep learning architectures for automatic feature learning.
\end{itemize}

\subsection*{ML Approach}
\begin{itemize}
    \item Built a deep learning model comprising 5 CNN layers followed by an LSTM layer to capture spatial and temporal features.
    \item Used dropout (0.1) for regularization.
    \item Extracted features automatically within the network, then classified using an SVM with RBF kernel.
    \item Employed 5-fold cross-validation for robust evaluation.
\end{itemize}
\subsection*{Results}
\begin{itemize}
    \item Maximum classification accuracy: 95.7\% (CNN-LSTM with SVM)
    \item Various architectures tested with accuracies ranging from 68\% to 95.7\%
    \item The combination of deep learning feature extraction with SVM classification outperformed using deep learning alone
    \item Highest accuracy reported so far for non-invasive diabetes detection using HRV signals
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item Limited dataset size could affect generalization; larger datasets are needed.
    \item Variability in HRV signals due to individual differences may pose challenges.
    \item Ensuring model interpretability for clinical acceptance.
    \item Moving from controlled datasets to real-world, noisy ECG signals.
\end{itemize}

\subsection*{Future Directions}
\begin{itemize}
    \item Increase dataset size to improve model accuracy and robustness.
    \item Explore anomaly prediction techniques by analyzing dynamic characteristics in HRV data.
    \item Develop more advanced deep learning models for early and accurate detection.
    \item Investigate applicability to real-time monitoring and broader clinical validation.
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item The dataset size is limited (only 20 individuals), which may affect the model's ability to generalize to larger populations
    \item Like other deep learning models, the interpretability of the model could be a concern for clinical use
\end{itemize}

% ============================== ARTICLE 5 =====================================
\section{Enhancing Heart Disease Prediction with Reinforcement Learning and Data Augmentation}
\textbf{Article Reference:} \cite{article_5}

\subsection*{Overview}
This study aims to improve the prediction accuracy of heart disease by integrating reinforcement learning (RL) and data augmentation techniques. The approach addresses the complexities of cardiac data, which often hampers traditional machine learning models, by leveraging advanced methods to enhance predictive performance and early diagnosis.

\subsection*{Dataset}
The primary dataset employed is similar to the Cleveland Heart Disease dataset, sourced from the UCI Machine Learning Repository. It contains features such as age, gender, blood pressure, cholesterol levels, ECG results, and other patient health indicators. The dataset includes a target variable indicating the presence or absence of heart disease, facilitating classification tasks. Additional datasets might come from healthcare agencies and research repositories.

\subsection*{Data Processing}
\begin{itemize}
    \item \textbf{Feature Selection:} Techniques such as feature importance scores and recursive feature elimination were used to identify the most impactful variables for heart disease prediction.
    \item \textbf{Data Augmentation:} Applied transformations like feature scaling, rotation, noise addition, and synthetic data generation to expand and diversify the training data. This helps models handle variability and reduce overfitting.
    \item \textbf{Model Training:} The models were trained on augmented data, using reinforcement learning strategies to iteratively improve predictions based on feedback.
    \item \textbf{Evaluation:} The models were assessed using metrics like accuracy, precision, recall, F1-score, and AUC-ROC scores to gauge performance and robustness.
\end{itemize}

\subsection*{ML Approach}
\begin{itemize}
    \item \textbf{Data Augmentation:} Applying transformations like feature scaling, rotation, noise addition, and synthetic data generation to expand and diversify the training data. This helps models handle variability and reduce overfitting.
    \item \textbf{Reinforcement Learning (RL):} Utilizing RL algorithms to optimize decision-making processes dynamically, allowing models to adapt to evolving patient data and improve prediction accuracy over time.
\end{itemize}

\noindent \textbf{How It Functions in the Study:}
\begin{itemize}
    \item \textbf{Initialization:}
        \begin{itemize}
            \item The RL agent starts with an initial policy, possibly based on prior knowledge or random actions.
            \item The dataset is preprocessed, and the model's initial parameters are set.
        \end{itemize}
    \item \textbf{Interaction Loop:}
        \begin{itemize}
            \item For each episode, the agent:
            \begin{itemize}
                \item Observes the current state (e.g., patient features).
                \item Selects an action according to its policy (e.g., choosing a specific augmentation or parameter setting).
                \item Executes the action, which may involve training the model further, updating parameters, or selecting data augmentation techniques.
                \item Moves to the next state, reflecting the outcome of its action, such as improved data representation or better predictive performance.
                \item Receives a reward based on the effectiveness of its action, such as increased accuracy or better generalization.
            \end{itemize}
        \end{itemize}
    \item \textbf{Learning:}
        \begin{itemize}
            \item The agent updates its policy based on the feedback (rewards), aiming to improve decision-making over future episodes.
            \item Techniques like Q-learning or policy gradients are often used to optimize this process.
        \end{itemize}
    \item \textbf{Outcome:}
        \begin{itemize}
            \item Over many iterations, the RL model learns which actions lead to higher rewards and adapts its strategy to improve heart disease prediction accuracy continually.
        \end{itemize}
\end{itemize}

\noindent In summary:
\begin{itemize}
    \item \textbf{States} represent patient data or model status.
    \item \textbf{Actions} correspond to decisions like data augmentation choices or model updates.
    \item \textbf{Rewards} are signals (e.g., accuracy improvements) guiding the learning process.
    \item The RL agent learns the best policy to update the model continuously, maximizing prediction performance.
\end{itemize}

\subsection*{Results}
\begin{itemize}
    \item Achieved an accuracy rate of approximately 94\%, surpassing traditional models
    \item Data augmentation contributed to better generalization and robustness
    \item Reinforcement learning facilitated continual improvement, especially in handling complex and dynamic cardiac data
    \item Significant gains in both recall and overall predictive performance
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item \textbf{Computational Complexity:} The combined methods demand significant processing power and longer training times.
    \item \textbf{Data Quality and Accessibility:} The efficacy of data augmentation depends heavily on the quality of the original dataset; biases or missing data can impact outcomes.
    \item \textbf{Model Generalizability:} Design choices and assumptions within the RL framework may limit applicability across diverse patient populations or clinical settings.
    \item \textbf{Scalability:} Handling large-scale, real-world datasets remains challenging due to resource requirements.
\end{itemize}

\subsection*{Future Directions}
\begin{itemize}
    \item \textbf{Fine-tuning Techniques:} Further optimizing model parameters and augmentation strategies.
    \item \textbf{Privacy and Security:} Incorporating mechanisms to ensure patient data privacy.
    \item \textbf{Clinical Validation:} Conducting extensive real-world clinical trials to validate model usefulness and safety.
    \item \textbf{Broader Application:} Extending the methodology to other medical diagnostic areas beyond heart disease.
    \item \textbf{Reducing Computational Costs:} Developing more efficient algorithms to make the approach more scalable and practical in healthcare settings.
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item The integration of RL and data augmentation is promising, but computational demands and reliance on data quality could hinder deployment in resource-limited settings.
    \item The paper lacks details on the exact RL algorithm used, which is essential for reproducibility.
    \item There is limited discussion on how interpretability is addressed, which is crucial for clinical use.
\end{itemize}

% ============================== ARTICLE 6 =====================================
\section{CardioXNet: A Novel Lightweight Deep Learning Framework for Cardiovascular Disease Classification Using Heart Sound Recordings}
\textbf{Article Reference:} \cite{article_6}

\subsection*{Overview}
This paper introduces CardioXNet, a lightweight CRNN architecture designed for the automatic detection of five types of heart sounds using raw PCG signals. The architecture involves two main phases: representation learning to extract time-invariant features and sequence residual learning to extract temporal features. CardioXNet is designed to be efficient for use in low-resource settings.

\subsection*{Dataset}
\begin{itemize}
    \item \textbf{Primary Dataset:} GitHub PCG database containing 1000 recordings across five classes: Normal, Aortic stenosis, Mitral regurgitation, Mitral stenosis, and Mitral valve prolapse.
    \item \textbf{Secondary Dataset:} PhysioNet/CinC 2016 challenge dataset with 3240 recordings labeled as normal or abnormal, used to test the model's generalizability.
\end{itemize}

\subsection*{Data Processing}
\begin{itemize}
    \item All signals were resampled at 2 kHz and amplitude-normalized
    \item No segmentation or extensive preprocessing was performed, emphasizing the model's robustness to raw signals
    \item The approach leverages convolutional pathways to learn features directly from raw waveforms, avoiding traditional MFCC or spectrogram conversion
\end{itemize}

\subsection*{ML Approach}
The authors developed CardioXNet, a lightweight CRNN framework with two learning schemes:
\begin{itemize}
    \item \textbf{Representation learning:} Extracts time-invariant features using three parallel CNN pathways
    \item \textbf{Sequence residual learning:} Extracts temporal features using bidirectional connections
    \item The model is specifically designed to be efficient in terms of parameters and computational requirements
\end{itemize}

\subsection*{Results}
\begin{itemize}
    \item Achieved 99.60\% accuracy on the GitHub dataset, outperforming prior methods.
    \item Demonstrated 86.57\% accuracy on the PhysioNet dataset, indicating good generalization.
    \item Model is efficient, with only 0.67M trainable parameters, 26M FLOPS, and $\sim$54.6 ms processing time—suitable for real-time applications.
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item Limited dataset size, especially for specific conditions like HVD
    \item Lack of patient independence and demographic details
    \item Generalization to real-world, heterogeneous data remains untested
\end{itemize}

\subsection*{Future Directions}
\begin{itemize}
    \item Incorporate larger and more diverse PCG datasets
    \item Integrate CardioXNet into wearable devices with cloud connectivity
    \item Explore transfer learning and further model compression for resource-constrained deployment
    \item Develop methods to handle noisy recordings and variable acoustic environments
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item Dataset size and diversity might limit generalizability to broader populations
    \item Missing demographic and variability information limits assessment of performance across different patient groups
    \item Robustness to real-world noise and device variation not fully evaluated
    \item Limited evaluation in actual clinical settings
\end{itemize}

% ============================== ARTICLE 7 =====================================
\section{A Reinforcement Learning–Based Method for Management of Type 1 Diabetes: Exploratory Study}
\textbf{Article Reference:} \cite{article_7}

\subsection*{Overview}
The researchers developed a reinforcement learning (RL) framework, specifically a Q-learning algorithm, to personalize insulin dosing for patients with Type 1 Diabetes Mellitus (T1DM). The aim was to improve blood glucose management by recommending insulin doses tailored to individual patient characteristics.

\subsection*{Dataset}
The dataset consisted of clinical records from 87 T1DM patients treated at Mass General Hospital (MGH) between 2003 and 2013.

The data included patient information such as HbA1c levels, BMI, physical activity, and alcohol usage.

The authors conducted a correlation analysis to identify key variables influencing blood glucose, concluding that HbA1c, BMI, activity level, and alcohol usage were the most relevant.

Based on these factors, they defined the patient’s state by discretizing these variables into levels:
    \begin{itemize}
        \item HbA1c levels (e.g., normal, elevated, high)
        \item BMI categories
        \item Activity levels (e.g., low, high)
        \item Alcohol usage levels (e.g., none, moderate, high)
    \end{itemize}

\subsection*{Data Processing}
States were formed as combinations of these discretized features.

Insulin doses (actions) were defined within specific ranges (e.g., Lantus dose intervals).

The data was used to train and validate the RL model.

\subsection*{Approach}
\textbf{Framework \& Method:}
\begin{itemize}
    \item The Q-learning algorithm was employed, which is a model-free RL method.
    \item The environment is represented by the patient’s health state, and the agent makes decisions on insulin dosage.
    \item The states are defined by the combination of HbA1c, BMI, activity level, and alcohol usage.
    \item The actions are discretized insulin dose levels (specific dose intervals).
    \item The reward function is designed based on how well the insulin dose achieved the target HbA1c level.
\end{itemize}

\subsection*{ML Approach}
\begin{itemize}
    \item At each time step (e.g., clinical visit), the agent observes the state and selects an action (insulin dose) either by exploration (random choice with probability $\epsilon$) or exploitation (based on learned Q-values).
    \item After administering the dose, the patient's response (e.g., change in HbA1c) results in a reward, guiding the learning process.
    \item The Q-values are updated iteratively based on the reward and the estimated value of subsequent states.
\end{itemize}

\subsection*{Results}
\begin{itemize}
    \item RL model tested on 60 unseen cases
    \item Recommended insulin dose interval included the physician-prescribed dose in 88\% of cases
    \item Results suggest the RL approach can effectively offer personalized treatment recommendations aligning with clinical decisions
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item \textbf{Limited dataset size:} Only 87 patients, which may limit generalizability
    \item \textbf{Discretization of variables:} Fineness of categories might affect the model's precision
    \item \textbf{Data quality and missing variables:} Not all potentially influential factors (like diet or stress) were included
    \item \textbf{Algorithm complexity:} RL models require careful tuning; real-world implementation must address issues like exploration vs. exploitation and patient safety
\end{itemize}

\subsection*{Future Directions}
\begin{itemize}
    \item Extend the model to include other types of insulin and medications
    \item Incorporate finer categories or continuous variables for more precise recommendations
    \item Validate with larger and more diverse datasets
    \item Explore application to other populations, such as patients with Type 2 Diabetes
    \item Implement real-time decision support in clinical settings
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item Limited patient sample size may not capture all variability in diabetes management
    \item Discretization may lead to loss of information that could be valuable for precise dosing
    \item No explicit mention of model validation techniques beyond testing on 60 cases
    \item Reward function description is brief; more detail would clarify alignment with clinical goals
\end{itemize}

% ============================== ARTICLE 8 =====================================
\section{Cardiovascular Diseases Prediction by Machine Learning Incorporation with Deep Learning}
\textbf{Article Reference:} \cite{article_8}

\subsection*{Overview}
The article discusses the increasing role of artificial intelligence (AI) in healthcare, particularly in predicting cardiovascular diseases (CVD). It highlights the growing prevalence of data from the Internet of Things (IoT) within healthcare systems, which can be leveraged to identify risk factors associated with CVD.

\subsection*{Dataset}
\begin{itemize}
    \item Heart dataset with 918 unique samples after removing duplicates
    \item Dataset comprises 11 features relevant for predicting CVD
\end{itemize}

\subsection*{Data Processing}
The study employed machine learning models to analyze the data received from Internet of Things (IoT) devices. Traditional machine learning algorithms were noted to have limitations in accuracy, which led to the exploration of advanced techniques for better predictions. A feature selection method using Tree SHAP was applied to identify significant features influencing CVD predictions. This method enhances the interpretability of the results by showing each feature's contribution to predictions.

\subsection*{Approach}
The researchers proposed a stacking fusion model-based classifier, which achieved an impressive accuracy of nearly 96\%. This model effectively combined the strengths of various algorithms, outperforming individual models in predicting high-risk individuals for CVD. They emphasized the limitations of traditional machine learning and the importance of large, diverse datasets for robust predictions.

\subsection*{Results}
The proposed stacking fusion model-based classifier demonstrated superior performance, achieving nearly 96\% accuracy. The model's performance remained stable after feature selection, with AUC values not significantly impacted by the removal of the Resting ECG feature.

\subsection*{Challenges}
One of the challenges noted in the study is the reliance on traditional machine learning algorithms, which may not adequately account for data variability, leading to lower accuracy in predictions. Additionally, the need for more extensive datasets from various medical institutions was emphasized.

\subsection*{Future Directions}
\begin{itemize}
    \item Incorporate additional deep learning techniques within IoT environments
    \item Enhance accuracy for identifying high-risk patients
    \item Implement early clinical interventions based on model predictions
    \item Develop more sophisticated models that can handle real-time streaming data
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item Need for broader dataset diversity incorporating various demographics and geographical locations
    \item More detailed explanation of the specific algorithms used in the stacking model would clarify their individual contributions
    \item Longitudinal studies would help assess the real-world effectiveness of the models
    \item The paper does not adequately address how data imbalance was handled
\end{itemize}

% ============================== ARTICLE 9 =====================================
\section{Optimizing Type 2 Diabetes Management: AI-Enhanced Time Series Analysis of Continuous Glucose Monitoring Data for Personalized Dietary Intervention}
\textbf{Article Reference:} \cite{article_9}

\subsection*{Overview}
This study proposes a method to optimize type 2 diabetes management using AI-enhanced time series analysis of continuous glucose monitoring (CGM) data. The goal is to enable personalized dietary interventions to improve patient outcomes.

\subsection*{Dataset}
\begin{itemize}
    \item Collected CGM data from 8 patients with type 2 diabetes.
    \item Data includes time-series blood glucose (BG) values.
\end{itemize}

\subsection*{Data Processing}
\begin{itemize}
    \item Removed NaN records to clean the data.
    \item Applied feature extraction and dimensionality reduction techniques.
    \item Split dataset into training (75\%) and testing (25\%) portions.
\end{itemize}

\subsection*{ML Approach}
\begin{itemize}
    \item Used regression models: XGBoost, SARIMA, Prophet.
    \item Evaluated using MAE, MSE, and R-squared (R²) metrics.
    \item Integrated dietary recommendations based on predicted BG levels.
\end{itemize}

\subsection*{Results}
\begin{itemize}
    \item XGBoost outperformed SARIMA and Prophet.
    \item Achieved high R² and low MAPE.
    \item Accurately predicted glucose fluctuations for timely intervention.
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item Limited dataset (only 8 patients) reduced model generalizability.
    \item Up to ±30-minute lag in CGM readings affected prediction accuracy.
\end{itemize}

\subsection*{Future Directions}
\begin{itemize}
    \item Expand dataset to improve training and validation.
    \item Enhance model with additional features and contextual data.
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item Promising approach, but small sample limits robustness.
    \item Time lag in CGM data must be addressed for better accuracy.
\end{itemize}

% ============================== ARTICLE 9 =====================================
\section{Optimizing Type 2 Diabetes Management: AI-Enhanced Time Series Analysis of Continuous Glucose Monitoring Data for Personalized Dietary Intervention}
\textbf{Article Reference:} \cite{article_9}

\subsection*{Overview}
This study proposes a method to optimize type 2 diabetes management using AI-enhanced time series analysis of continuous glucose monitoring (CGM) data. The goal is to enable personalized dietary interventions to improve patient outcomes.

\subsection*{Dataset}
\begin{itemize}
    \item Collected CGM data from 8 patients with type 2 diabetes.
    \item Data includes time-series blood glucose (BG) values.
\end{itemize}

\subsection*{Data Processing}
\begin{itemize}
    \item Removed NaN records to clean the data.
    \item Applied feature extraction and dimensionality reduction techniques.
    \item Split dataset into training (75\%) and testing (25\%) portions.
\end{itemize}

\subsection*{ML Approach}
\begin{itemize}
    \item Used regression models: XGBoost, SARIMA, Prophet.
    \item Evaluated using MAE, MSE, and R-squared (R²) metrics.
    \item Integrated dietary recommendations based on predicted BG levels.
\end{itemize}

\subsection*{Results}
\begin{itemize}
    \item XGBoost outperformed SARIMA and Prophet.
    \item Achieved high R² and low MAPE.
    \item Accurately predicted glucose fluctuations for timely intervention.
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item Limited dataset (only 8 patients) reduced model generalizability.
    \item Up to ±30-minute lag in CGM readings affected prediction accuracy.
\end{itemize}

\subsection*{Future Directions}
\begin{itemize}
    \item Expand dataset to improve training and validation.
    \item Enhance model with additional features and contextual data.
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item Promising approach, but small sample limits robustness.
    \item Time lag in CGM data must be addressed for better accuracy.
\end{itemize}

% ============================== ARTICLE 10 =====================================
\section{Deep Q-Network (DQN) Model for Disease Prediction Using Electronic Health Records (EHRs)}
\textbf{Article Reference:} \cite{article_10}

\subsection*{Overview}
The paper addresses the challenges of using deep learning models for disease prediction with EHRs, including lack of precision, ethical concerns, limitations of small datasets, complexity of data processing, and incompleteness of patient data. It proposes a deep Q-learning (DQL) model to enhance the accuracy and stability of predictions. The model integrates reinforcement learning with neural networks, utilizing the mapping capabilities of the Q-network. The proposed model is evaluated on the Heart Disease Dataset from the UCI Data Repository, demonstrating high accuracy (98\%) compared to other models.

\subsection*{Dataset}
\begin{itemize}
    \item The Heart Disease Dataset from the UCI Data Repository via Kaggle.
    \item Includes multivariate numerical data with 14 attributes (categorical, integer, and real data).
\end{itemize}

\subsection*{Data Processing}
\begin{itemize}
    \item The dataset was split into training (80\%) and test sets (20\%) using stratified splitting.
    \item Robust scaling was applied for feature scaling.
\end{itemize}

\subsection*{ML Approach}
\begin{itemize}
    \item The study uses a Deep Q-Network (DQN) model, which combines reinforcement learning with neural networks.
    \item This approach aims to address the limitations of traditional Q-learning and improve the accuracy and stability of disease predictions.
\end{itemize}

\subsection*{Implementation of Reinforcement Learning}
\begin{itemize}
    \item The model uses a "disease prediction game" environment.
    \item State: The state is represented by the samples from the EHR data.
    \item Action: Actions involve increasing, decreasing, or holding each feature.
    \item Reward: Positive rewards are given for accurate predictions, and negative rewards for inaccurate ones.
    \item Environment: The environment consists of sets of states (samples) and actions (feature adjustments).
\end{itemize}

\subsection*{Results}
\begin{itemize}
    \item The paper compares the Deep Q-Network (DQN) model with Logistic Regression, Decision Tree Classifier, Random Forest Classifier, and Gradient-Boosting Classifier.
\end{itemize}

Key Results:
\begin{itemize}
    \item The proposed EHR-DQN model achieved high accuracy (0.9841) and a low mean squared error (MSE) of 0.0001.
    \item The Decision Tree and Gradient-Boosting Classifiers also performed well, with perfect precision, recall, and F1 scores.
    \item The Random Forest model showed a balance of high accuracy (0.9783) and a minimal MSE of 0.
    \item Logistic Regression had the lowest performance, with an accuracy of 0.8424 and a higher MSE of 0.1576.
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item Data-related issues: digitization, consolidation, and availability of health records.
    \item Privacy and legal concerns with patient data handling.
    \item Patient-related difficulties: decision-making errors, treatment errors, and data inconsistencies.
    \item Technical challenges: data integration across systems, ensuring patient security.
    \item Interpretability: "black box" nature of complex AI models limits transparency.
    \item Resource limitations: computational resources and expertise needed for implementation.
\end{itemize}

\subsection*{Future Directions}
\begin{itemize}
    \item Expand the dataset size to better train deep reinforcement learning models.
    \item Integrate additional contextual features to improve prediction accuracy.
    \item Develop more transparent models to address interpretability concerns.
    \item Create more standardized methods for validating healthcare AI systems.
    \item Improve integration with clinical workflows for practical implementation.
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item The paper emphasizes the high accuracy of the proposed model but also points out that the dataset used has only thousands of samples. The DQN algorithm typically requires a large number of training samples (millions) to achieve optimal performance.
    \item The paper acknowledges the "black box" nature of many AI algorithms and the resulting lack of interpretability, which can hinder trust and adoption in healthcare.
\end{itemize}

% ============================== ARTICLE 11 =====================================
\section{A Reinforcement Learning Model for AI-Based Decision Support in Skin Cancer}
\textbf{Article Reference:} \cite{article_11}

\subsection*{Overview}
\begin{itemize}
    \item The article presents a reinforcement learning (RL) model designed to enhance decision support in skin cancer diagnosis.
    \item It compares the effectiveness of RL with supervised learning (SL) methods, emphasizing the potential of RL in optimizing management decisions.
\end{itemize}

\subsection*{Dataset}
\begin{itemize}
    \item They utilized the publicly available HAM10000 dataset, a comprehensive collection of dermatoscopic images of skin lesions.
    \item This dataset contains over 10,000 images across seven diagnostic categories of skin lesions.
\end{itemize}

\subsection*{Data Processing}
\begin{itemize}
    \item For patient-centered scenarios, input vectors were normalized by dividing position-wise by the average across all lesion vectors of the same patient.
    \item This normalization was crucial for processing multiple lesions from the same patient effectively.
    \item Feature extraction was performed using convolutional neural networks pre-trained on the dataset.
\end{itemize}

\subsection*{ML Approach}
\begin{itemize}
    \item Supervised Learning (SL): A convolutional neural network was fine-tuned for classifying seven categories of skin lesions.
    \item Reinforcement Learning (RL): A deep Q-learning model was developed using a multilayer perceptron that processed feature vectors derived from the SL model.
    \item They also implemented a threshold-based approach for comparison.
\end{itemize}

\subsection*{Implementation of Reinforcement Learning}
\begin{itemize}
    \item States: One-dimensional vectors representing features of skin lesions.
    \item Actions: Management strategies including excision, short-term follow-up, and regular surveillance.
    \item Rewards: Defined based on diagnosis outcomes and management decisions, optimizing for both clinical efficacy and resource utilization.
    \item Learning: The model used experience replay and target networks to stabilize learning.
\end{itemize}

\subsection*{Results}
\begin{itemize}
    \item The RL method and threshold method both improved management decisions compared to the naïve SL model.
    \item Both approaches optimized operating points on decision curves, enhancing diagnostic accuracy.
    \item The RL model demonstrated superior performance in balancing sensitivity and specificity.
    \item The study showed potential for reducing unnecessary excisions while maintaining high detection rates.
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item RL models require more complex retraining compared to simpler threshold approaches.
    \item Integration into clinical workflows presents practical implementation barriers.
    \item Limited consideration of patient preferences in the current model design.
    \item Lack of longitudinal data to validate long-term decision outcomes.
\end{itemize}

\subsection*{Future Directions}
\begin{itemize}
    \item Development of reward tables incorporating both physician and patient preferences.
    \item Enhancement of shared decision-making tools combining AI recommendations with clinical expertise.
    \item Integration of additional clinical parameters beyond image data.
    \item Validation in prospective clinical trials to assess real-world impact.
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item It focuses primarily on physician preferences, potentially neglecting patient-centered care principles.
    \item Limited dataset diversity may restrict generalizability across different patient populations.
    \item The complexity of RL models may limit practical implementation in resource-constrained settings.
    \item Further validation is needed to demonstrate clinical utility beyond technical performance metrics.
\end{itemize}

% ============================== COMPARISON TABLE ==============================
\section{Comparison of the Solutions}
\begin{table}[htbp]
\begin{adjustwidth}{-2cm}{-2cm}
\centering
\scriptsize
\begin{tabular}{|p{1.5cm}|p{2.5cm}|p{3cm}|p{3.5cm}|p{2.5cm}|p{2.5cm}|}
\hline
\textbf{Work} & \textbf{Disease/Domain} & \textbf{Dataset} & \textbf{Data Processing} & \textbf{Approach} & \textbf{Results} \\
\hline
\cite{article_1} & Epilepsy & Phase III (235) + Validation (47) patients & Clinical + WGS feature extraction (e.g., SV2A), mutational scores, PRS & Gradient-Boosted Decision Trees & AUC: 0.76 (train), 0.75 (validation) \\
\hline
\cite{article_2} & Diabetes Prediction & Pima Indian (768) + RTML (203) records & Imputation, ADASYN, Mutual Info, Holdout Validation & XGBoost + Ensemble Methods (voting, bagging) & AUC: 0.84, Accuracy: 81\%, F1 Score: 0.81 \\
\hline
\cite{article_3} & Alzheimer's Disease & Wearable sensors and motion capture data & Normalization, median imputation, SMOTE, RFE, correlation analysis & Hybrid CNN-RNN (LSTM) & Accuracy: 93\%, Precision: 92\%, Recall: 91\%, F1-Score: 91.5\%, AUC-ROC: 95\% \\
\hline
\cite{article_4} & Diabetes & ECG recordings (71 datasets) & Pan-Tompkins for QRS detection & CNN-LSTM + SVM & Accuracy: 95.7\% \\
\hline
\cite{article_5} & Heart Disease & UCI Cleveland Heart Disease dataset & Feature selection, data augmentation, reinforcement-based iteration & RL + Data Augmentation & Accuracy: 94\% \\
\hline
\cite{article_6} & Cardiovascular Disease & PCG datasets (GitHub + PhysioNet) & Minimal preprocessing on raw heart sound signals & Lightweight CRNN (CardioXNet) with dual learning (representation + sequence residual) & Accuracy: 99.6\% (GitHub), 86.57\% (PhysioNet), 0.67M params, $\sim$54.6ms latency \\
\hline
\cite{article_7} & Type 1 Diabetes & Clinical data from 87 patients (MGH, 2003–2013) & Discretization of HbA1c, BMI, activity level, alcohol usage into states & Q-Learning (model-free RL) for insulin dosing & 88\% RL suggestions matched physician dose \\
\hline
\cite{article_8} & Cardiovascular Disease & Heart dataset (918 samples, 11 features) & Duplicate removal, Tree SHAP feature selection & Stacking fusion model with IoT-enhanced data inputs & Accuracy: 96\%, Stable AUC after feature pruning \\
\hline
\cite{article_9} & Type 2 Diabetes & CGM data from 8 patients & NaN removal, feature extraction, dimensionality reduction, 75/25 train-test split & XGBoost, SARIMA, Prophet regression for BG prediction + dietary recommendations & XGBoost: High R², low MAPE, effective BG prediction for personalized intervention \\
\hline
\cite{article_10} & Heart Disease & UCI Heart Disease Dataset via Kaggle (14 attributes) & Stratified 80/20 train-test split with robust scaling & Deep Q-Network (DQN) with reinforcement learning & Accuracy: 98.41\%, MSE: 0.0001, outperformed traditional classifiers \\
\hline
\cite{article_11} & Skin Cancer & HAM10000 dataset (10,000+ dermatoscopic images) & Feature extraction via CNN, patient-level normalization for multiple lesions & Comparative RL (Deep Q-learning) vs SL (CNN) for decision support & Improved diagnostic and management decisions, optimal operating points on decision curves \\
\hline
\end{tabular}
\caption{Comparison of AI Approaches in Health Applications}
\label{tab:ai_health_comparison}
\end{adjustwidth}
\end{table}

% \newpage
% \section{Discussion}
% As presented in the table above, different methods were proposed using machine learning which are seen as the most effective technique to build an intrusion detection system and detect attacks with different datasets mostly NSL-KDD dataset which resulted in a good accuracy.\\
% Nearly half of the studies did not work with normalization, there are also studies that did not perform a feature selection, as well as the most did not test many learning algorithms and the most of studies work on binary classification (normal or attack).

 
% \section{Conclusion}
% In this chapter, we studied and evaluated the latest methods proposed by recent research, about the use of machine learning methods for attacks classification based on data-sets.

% Most of the studied architectures could more or less achieve satisfying results with high accuracy. However, further research using large and fresh data-sets is always required to improve the performance of the existing methods for more efficient results.



