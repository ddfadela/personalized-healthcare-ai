%-----------------------------------------------------------------------------------------------------------------------------
% \chapter{Machine Learning-Based Intrusion Detection System Approaches}
% This section will provide an overview of various approaches that have been developed for intrusion detection.
% Many works are being carried out in this context to find the best parameters and results for intrusion detection in various environments, and this survey will examine some of the most recent studies. The section will conclude with a summary table of the reviewed approaches.\\
% ============================== ARTICLE 1 =====================================
\section{Towards Realizing the Vision of Precision Medicine: AI-Based Prediction of Clinical Drug Response}
\textbf{Article Reference:} \cite{article_1}

\subsection*{Overview}
This study uses machine learning to predict patient response to the epilepsy drug brivaracetam using integrated clinical and genomic data. The resulting model demonstrated strong performance (AUC: 0.76 training, 0.75 validation) and identified specific biomarkers associated with poor response. The research underscores the potential of ML models to support precision medicine and optimize clinical trials by targeting likely responders. This study highlights the potential of AI to personalize treatment strategies in epilepsy by predicting drug response, a key aspect of personalized medicine.

\subsection*{Dataset}
\begin{itemize}
    \item \textbf{Discovery dataset:} 235 adult patients from a phase III clinical trial (NCT01261325).
    \item \textbf{External validation dataset:} 47 patients from an independent trial (NCT00490035).
\end{itemize}

\subsection*{Data Processing}
Clinical data included demographic and seizure-related information. Whole Genome Sequencing (WGS) data ($\sim$20 million variants) was filtered down to 40 features through knowledge-driven extraction, focusing on epilepsy-related genes and drug mechanism (e.g., SV2A gene, eQTLs). Genetic features included mutational load scores, polygenic risk scores, and structural variant descriptors.

\subsection*{ML Approach}
Multiple ML models were evaluated: sparse multi-block PLS-DA, multimodal neural networks, elastic net, gradient-boosted decision trees (GBDT), and stacked classifiers. The best performance was achieved using a GBDT model integrating all data types. GBDT models are well-suited for handling the complex interactions between clinical and genetic features, which is crucial for personalized drug response prediction. However, the inherent complexity of GBDT models can make it challenging to interpret the specific contributions of individual features, a limitation that future explainable AI (XAI) techniques could address.

\subsection*{Results}
\begin{itemize}
    \item AUC (training): 0.76
    \item AUC (validation): 0.75
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item Addressing high dimensionality and sparsity of genomic data. This is a common challenge in personalized medicine research, as genomic data often has many variables but few samples.
    \item Integrating additional data types (e.g., EEG, imaging) to improve model performance. Multimodal data integration is essential for a holistic view of the patient but increases complexity.
    \item Generalizing models to other anti-epileptic drugs. This is crucial for wider clinical applicability in personalized epilepsy treatment.
    \item Collaborating with regulatory bodies for clinical adoption. AI-driven personalized medicine tools require rigorous validation and regulatory approval for safe and effective use.
    \item Increasing dataset size to enhance model performance (targeting $\sim$350 patients for AUC = 0.9). Larger datasets are vital for building robust and generalizable predictive models in personalized healthcare.
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item The sample size, while sufficient for the study, could be larger to further enhance model performance and generalizability. 
    \item The complexity of the GBDT model, while providing good predictive power, makes it difficult to interpret the specific contributions of individual features.
    
\end{itemize}

% ============================== ARTICLE 2 =====================================
\section{Diabetes Prediction Using Machine Learning and Explainable AI Techniques}
\textbf{Article Reference:} \cite{article_2}

\subsection*{Overview}
This study proposes an automated diabetes prediction system using ML and explainable AI. The system combines the public Pima Indian dataset with a private dataset collected from female workers in a Bangladeshi textile factory. The system addresses data imbalance, missing values, and is deployed for real-time prediction via web and mobile applications. The development of non-invasive AI-driven tools for diabetes detection, as presented in this paper, contributes to personalized healthcare by enabling earlier and more accessible diagnosis.

\subsection*{Dataset}
\begin{itemize}
    \item \textbf{Pima Indian Dataset:} 768 records, 268 diabetes-positive; includes 8 features.
    \item \textbf{RTML Private Dataset:} 203 female employees; features similar to Pima dataset but lacks insulin values.
\end{itemize}

\subsection*{Data Processing}
\begin{itemize}
    \item Zero values in the merged dataset were replaced with corresponding mean values and the dataset was separated into training and test sets using the holdout validation technique.
    \item Mutual information was used to measure the interdependence of variables and feature importance.
    \item A semi-supervised approach using the extreme gradient boosting technique (XGB regressor) was used to predict the missing insulin feature of the RTML dataset.
\end{itemize}

\subsection*{ML Approach}
Various models were tested: decision trees, KNN, SVM, random forest, logistic regression, AdaBoost, XGBoost, bagging, and voting classifiers. Hyperparameters were tuned using GridSearchCV. The final model employed XGBoost with ADASYN for balancing. The choice of XGBoost is appropriate due to its effectiveness in handling complex datasets, but the lack of inherent explainability highlights the need for methods.

\subsection*{Results}
\begin{itemize}
    \item Accuracy: 81\%
    \item F1 Score: 0.81
    \item AUC: 0.84
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item Missing insulin values required imputation via semi-supervised learning. This introduces a degree of uncertainty into the model.
    \item Class imbalance necessitated oversampling (SMOTE, ADASYN). Oversampling techniques can sometimes lead to overfitting.
    \item Limited private dataset size may hinder generalizability. Larger, more diverse datasets would improve the robustness of the model.
\end{itemize}

\subsection*{Future Directions}
\begin{itemize}
    \item Expanding dataset size for better robustness.
    \item Integrating fuzzy logic and optimization for improved prediction.
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item The use of imputation for missing insulin values introduces some uncertainty.    
    \item The private dataset is relatively small, which may limit the model's generalizability.    
    
\end{itemize}

% ============================== ARTICLE 3 =====================================
\section{Integrating Machine Learning and Deep Learning Techniques for Advanced Alzheimer's Disease Detection through Gait Analysis}
\textbf{Article Reference:} \cite{article_3}

\subsection*{Overview}
The paper aims to enhance early detection of Alzheimer's Disease (AD) by leveraging gait analysis combined with advanced machine learning (ML) and deep learning (DL) techniques. Gait abnormalities, such as reduced stride length and irregular cadence, are identified as early biomarkers for cognitive decline associated with AD. The study emphasizes the need for non-invasive, scalable diagnostic tools. This research highlights the potential of AI-driven gait analysis to contribute to personalized AD management through early detection.

\subsection*{Dataset}
Data were collected using wearable sensors and motion capture systems in both clinical and real-world environments, providing high-resolution temporal and spatial gait metrics. The dataset includes gait features like stride length, cadence, swing time, and gait variability, with some data sourced from publicly available repositories like the UCI Machine Learning Repository.

\subsection*{Data Processing}
\begin{itemize}
    \item \textbf{Normalization:} Features were scaled between 0 and 1 to standardize the data, ensuring that features with larger ranges (e.g., stride length) did not dominate the model training.
    \item \textbf{Handling Missing Data:} Missing values were imputed using median substitution to maintain data integrity and reduce bias.
    \item \textbf{Class Imbalance:} The Synthetic Minority Over-sampling Technique (SMOTE) was applied to generate synthetic samples of the minority class (AD patients), addressing class imbalance issues.
    \item \textbf{Feature Selection:} Recursive Feature Elimination (RFE) was used to identify the most significant gait features—such as stride length, gait variability, and cadence—to improve model performance.
    \item \textbf{Correlation Analysis:} High correlations between key features (e.g., stride length and step length) validated their importance for prediction, informing feature selection.
\end{itemize}

\subsection*{ML Approach}
The study employed a hybrid deep learning model comprising Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) to classify individuals as healthy or at risk for AD. These models analyzed temporal-spatial gait features, capturing sequential patterns and irregularities. Traditional ML classifiers such as Random Forest and SVM were also evaluated for comparison. The use of a hybrid CNN-RNN model is a strength, as it leverages the capabilities of both CNNs for spatial feature extraction and RNNs for temporal sequence modeling, which is well-suited for gait analysis.

\subsection*{Results}
\begin{itemize}
    \item Hybrid CNN-RNN model accuracy: 93\%
    \item Precision: 92\% 
    \item Recall: 91\%
    \item F1-score: 91.5\%
    \item AUC-ROC: 95\%
    \item Traditional models: Random Forest (88\%) and SVM (86\%)
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item The reliance on controlled datasets, which may not fully reflect real-world variability, impacting model robustness.
    \item The complexity and interpretability of deep learning models, posing a barrier for clinical acceptance.
    \item The need for large, diverse datasets to ensure generalizability.
    \item Integration into clinical workflows and validation through real-world testing.
\end{itemize}

\subsection*{Future Directions}
\begin{itemize}
    \item Incorporating multimodal data sources, such as MRI, PET scans, vocal, and cognitive measures, to improve diagnostic precision.
    \item Expanding datasets to include diverse populations and environmental conditions, enhancing model robustness.
    \item Developing explainable AI frameworks to improve interpretability and clinician trust.
    \item Extending studies to include longitudinal gait data for monitoring disease progression and enabling earlier detection.
    \item Conducting clinical pilot studies and developing affordable wearable technologies for widespread, low-resource application.
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item The dataset may not fully represent the variability of real-world gait patterns.    
    \item Deep learning models are often considered "black boxes," which can hinder clinical acceptance.
\end{itemize}

% ============================== ARTICLE 4 =====================================
\section{Diabetes Detection Using Deep Learning Algorithms}
\textbf{Article Reference:} \cite{article_4}

\subsection*{Overview}
The authors developed a non-invasive method to detect diabetes using heart rate variability (HRV) signals derived from ECG data. They designed a deep learning architecture combining convolutional neural networks (CNN) and long short-term memory (LSTM) networks to automatically extract complex features from the HRV signals. These features were then classified using a support vector machine (SVM) with an RBF kernel. The approach achieved a high accuracy of 95.7\%, outperforming previous methods. This research demonstrates the potential of AI for non-invasive, personalized diabetes screening.

\subsection*{Dataset}
\begin{itemize}
    \item ECG recordings from 20 individuals (both diabetic and normal)
    \item Each participant provided a 10-minute ECG sample, from which heart rate time series data was derived
    \item Total datasets: 71 datasets for both groups, each containing 1000 samples
\end{itemize}

\subsection*{Data Processing}
\begin{itemize}
    \item Used Pan and Tompkins algorithm for QRS complex detection to extract heart rate intervals.
    \item Derived HRV signals directly from ECG without additional preprocessing.
    \item Input data fed into deep learning architectures for automatic feature learning.
\end{itemize}

\subsection*{ML Approach}
\begin{itemize}
    \item Built a deep learning model comprising 5 CNN layers followed by an LSTM layer to capture spatial and temporal features.
    \item Used dropout (0.1) for regularization.
    \item Extracted features automatically within the network, then classified using an SVM with RBF kernel.
    \item Employed 5-fold cross-validation for robust evaluation.
\end{itemize}
\subsection*{Results}
\begin{itemize}
    \item Maximum classification accuracy: 95.7\% (CNN-LSTM with SVM)
    \item Various architectures tested with accuracies ranging from 68\% to 95.7\%
    \item The combination of deep learning feature extraction with SVM classification outperformed using deep learning alone
    \item Highest accuracy reported so far for non-invasive diabetes detection using HRV signals
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item Limited dataset size could affect generalization; larger datasets are needed.
    \item Variability in HRV signals due to individual differences may pose challenges.
    \item Ensuring model interpretability for clinical acceptance.
    \item Moving from controlled datasets to real-world, noisy ECG signals.
\end{itemize}

\subsection*{Future Directions}
\begin{itemize}
    \item Increase dataset size to improve model accuracy and robustness.
    \item Explore anomaly prediction techniques by analyzing dynamic characteristics in HRV data.
    \item Develop more advanced deep learning models for early and accurate detection.
    \item Investigate applicability to real-time monitoring and broader clinical validation.
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item The dataset size is limited (only 20 individuals), which may affect the model's ability to generalize to larger populations
    \item Like other deep learning models, the interpretability of the model could be a concern for clinical use
\end{itemize}

% ============================== ARTICLE 5 =====================================
\section{Enhancing Heart Disease Prediction with Reinforcement Learning and Data Augmentation}
\textbf{Article Reference:} \cite{article_5}

\subsection*{Overview}
This study aims to improve the prediction accuracy of heart disease by integrating reinforcement learning (RL) and data augmentation techniques. The approach addresses the complexities of cardiac data, which often hampers traditional machine learning models, by leveraging advanced methods to enhance predictive performance and early diagnosis.

\subsection*{Dataset}
The primary dataset employed is similar to the Cleveland Heart Disease dataset, sourced from the UCI Machine Learning Repository. It contains features such as age, gender, blood pressure, cholesterol levels, ECG results, and other patient health indicators. The dataset includes a target variable indicating the presence or absence of heart disease, facilitating classification tasks. Additional datasets might come from healthcare agencies and research repositories.

\subsection*{Data Processing}
\begin{itemize}
    \item \textbf{Feature Selection:} Techniques such as feature importance scores and recursive feature elimination were used to identify the most impactful variables for heart disease prediction.
    \item \textbf{Data Augmentation:} Applied transformations like feature scaling, rotation, noise addition, and synthetic data generation to expand and diversify the training data. This helps models handle variability and reduce overfitting.
    \item \textbf{Model Training:} The models were trained on augmented data, using reinforcement learning strategies to iteratively improve predictions based on feedback.
    \item \textbf{Evaluation:} The models were assessed using metrics like accuracy, precision, recall, F1-score, and AUC-ROC scores to gauge performance and robustness.
\end{itemize}

\subsection*{ML Approach}
\begin{itemize}
    \item \textbf{Data Augmentation:} Applying transformations like feature scaling, rotation, noise addition, and synthetic data generation to expand and diversify the training data. This helps models handle variability and reduce overfitting.
    \item \textbf{Reinforcement Learning (RL):} Utilizing RL algorithms to optimize decision-making processes dynamically, allowing models to adapt to evolving patient data and improve prediction accuracy over time.
\end{itemize}

\noindent \textbf{How It Functions in the Study:}
\begin{itemize}
    \item \textbf{Initialization:}
        \begin{itemize}
            \item The RL agent starts with an initial policy, possibly based on prior knowledge or random actions.
            \item The dataset is preprocessed, and the model's initial parameters are set.
        \end{itemize}
    \item \textbf{Interaction Loop:}
        \begin{itemize}
            \item For each episode, the agent:
            \begin{itemize}
                \item Observes the current state (e.g., patient features).
                \item Selects an action according to its policy (e.g., choosing a specific augmentation or parameter setting).
                \item Executes the action, which may involve training the model further, updating parameters, or selecting data augmentation techniques.
                \item Moves to the next state, reflecting the outcome of its action, such as improved data representation or better predictive performance.
                \item Receives a reward based on the effectiveness of its action, such as increased accuracy or better generalization.
            \end{itemize}
        \end{itemize}
    \item \textbf{Learning:}
        \begin{itemize}
            \item The agent updates its policy based on the feedback (rewards), aiming to improve decision-making over future episodes.
            \item Techniques like Q-learning or policy gradients are often used to optimize this process.
        \end{itemize}
    \item \textbf{Outcome:}
        \begin{itemize}
            \item Over many iterations, the RL model learns which actions lead to higher rewards and adapts its strategy to improve heart disease prediction accuracy continually.
        \end{itemize}
\end{itemize}

\noindent In summary:
\begin{itemize}
    \item \textbf{States} represent patient data or model status.
    \item \textbf{Actions} correspond to decisions like data augmentation choices or model updates.
    \item \textbf{Rewards} are signals (e.g., accuracy improvements) guiding the learning process.
    \item The RL agent learns the best policy to update the model continuously, maximizing prediction performance.
\end{itemize}

\subsection*{Results}
\begin{itemize}
    \item Achieved an accuracy rate of approximately 94\%, surpassing traditional models
    \item Data augmentation contributed to better generalization and robustness
    \item Reinforcement learning facilitated continual improvement, especially in handling complex and dynamic cardiac data
    \item Significant gains in both recall and overall predictive performance
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item \textbf{Computational Complexity:} The combined methods demand significant processing power and longer training times.
    \item \textbf{Data Quality and Accessibility:} The efficacy of data augmentation depends heavily on the quality of the original dataset; biases or missing data can impact outcomes.
    \item \textbf{Model Generalizability:} Design choices and assumptions within the RL framework may limit applicability across diverse patient populations or clinical settings.
    \item \textbf{Scalability:} Handling large-scale, real-world datasets remains challenging due to resource requirements.
\end{itemize}

\subsection*{Future Directions}
\begin{itemize}
    \item \textbf{Fine-tuning Techniques:} Further optimizing model parameters and augmentation strategies.
    \item \textbf{Privacy and Security:} Incorporating mechanisms to ensure patient data privacy.
    \item \textbf{Clinical Validation:} Conducting extensive real-world clinical trials to validate model usefulness and safety.
    \item \textbf{Broader Application:} Extending the methodology to other medical diagnostic areas beyond heart disease.
    \item \textbf{Reducing Computational Costs:} Developing more efficient algorithms to make the approach more scalable and practical in healthcare settings.
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item The integration of RL and data augmentation is promising, but computational demands and reliance on data quality could hinder deployment in resource-limited settings.
    \item The paper lacks details on the exact RL algorithm used, which is essential for reproducibility.
    \item There is limited discussion on how interpretability is addressed, which is crucial for clinical use.
\end{itemize}

% ============================== ARTICLE 6 =====================================
\section{CardioXNet: A Novel Lightweight Deep Learning Framework for Cardiovascular Disease Classification Using Heart Sound Recordings}
\textbf{Article Reference:} \cite{article_6}

\subsection*{Overview}
This paper introduces CardioXNet, a lightweight CRNN architecture designed for the automatic detection of five types of heart sounds using raw PCG signals. The architecture involves two main phases: representation learning to extract time-invariant features and sequence residual learning to extract temporal features. CardioXNet is designed to be efficient for use in low-resource settings.

\subsection*{Dataset}
\begin{itemize}
    \item \textbf{Primary Dataset:} GitHub PCG database containing 1000 recordings across five classes: Normal, Aortic stenosis, Mitral regurgitation, Mitral stenosis, and Mitral valve prolapse.
    \item \textbf{Secondary Dataset:} PhysioNet/CinC 2016 challenge dataset with 3240 recordings labeled as normal or abnormal, used to test the model's generalizability.
\end{itemize}

\subsection*{Data Processing}
\begin{itemize}
    \item All signals were resampled at 2 kHz and amplitude-normalized
    \item No segmentation or extensive preprocessing was performed, emphasizing the model's robustness to raw signals
    \item The approach leverages convolutional pathways to learn features directly from raw waveforms, avoiding traditional MFCC or spectrogram conversion
\end{itemize}

\subsection*{ML Approach}
The authors developed CardioXNet, a lightweight CRNN framework with two learning schemes:
\begin{itemize}
    \item \textbf{Representation learning:} Extracts time-invariant features using three parallel CNN pathways
    \item \textbf{Sequence residual learning:} Extracts temporal features using bidirectional connections
    \item The model is specifically designed to be efficient in terms of parameters and computational requirements
\end{itemize}

\subsection*{Results}
\begin{itemize}
    \item Achieved 99.60\% accuracy on the GitHub dataset, outperforming prior methods.
    \item Demonstrated 86.57\% accuracy on the PhysioNet dataset, indicating good generalization.
    \item Model is efficient, with only 0.67M trainable parameters, 26M FLOPS, and $\sim$54.6 ms processing time—suitable for real-time applications.
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item Limited dataset size, especially for specific conditions like HVD
    \item Lack of patient independence and demographic details
    \item Generalization to real-world, heterogeneous data remains untested
\end{itemize}

\subsection*{Future Directions}
\begin{itemize}
    \item Incorporate larger and more diverse PCG datasets
    \item Integrate CardioXNet into wearable devices with cloud connectivity
    \item Explore transfer learning and further model compression for resource-constrained deployment
    \item Develop methods to handle noisy recordings and variable acoustic environments
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item Dataset size and diversity might limit generalizability to broader populations
    \item Missing demographic and variability information limits assessment of performance across different patient groups
    \item Robustness to real-world noise and device variation not fully evaluated
    \item Limited evaluation in actual clinical settings
\end{itemize}

% ============================== ARTICLE 7 =====================================
\section{A Reinforcement Learning–Based Method for Management of Type 1 Diabetes: Exploratory Study}
\textbf{Article Reference:} \cite{article_7}

\subsection*{Overview}
The researchers developed a reinforcement learning (RL) framework, specifically a Q-learning algorithm, to personalize insulin dosing for patients with Type 1 Diabetes Mellitus (T1DM). The aim was to improve blood glucose management by recommending insulin doses tailored to individual patient characteristics.

\subsection*{Dataset}
The dataset consisted of clinical records from 87 T1DM patients treated at Mass General Hospital (MGH) between 2003 and 2013.

The data included patient information such as HbA1c levels, BMI, physical activity, and alcohol usage.

The authors conducted a correlation analysis to identify key variables influencing blood glucose, concluding that HbA1c, BMI, activity level, and alcohol usage were the most relevant.

Based on these factors, they defined the patient’s state by discretizing these variables into levels:
    \begin{itemize}
        \item HbA1c levels (e.g., normal, elevated, high)
        \item BMI categories
        \item Activity levels (e.g., low, high)
        \item Alcohol usage levels (e.g., none, moderate, high)
    \end{itemize}

\subsection*{Data Processing}
States were formed as combinations of these discretized features.

Insulin doses (actions) were defined within specific ranges (e.g., Lantus dose intervals).

The data was used to train and validate the RL model.

\subsection*{Approach}
\textbf{Framework \& Method:}
\begin{itemize}
    \item The Q-learning algorithm was employed, which is a model-free RL method.
    \item The environment is represented by the patient’s health state, and the agent makes decisions on insulin dosage.
    \item The states are defined by the combination of HbA1c, BMI, activity level, and alcohol usage.
    \item The actions are discretized insulin dose levels (specific dose intervals).
    \item The reward function is designed based on how well the insulin dose achieved the target HbA1c level.
\end{itemize}

\subsection*{ML Approach}
\begin{itemize}
    \item At each time step (e.g., clinical visit), the agent observes the state and selects an action (insulin dose) either by exploration (random choice with probability $\epsilon$) or exploitation (based on learned Q-values).
    \item After administering the dose, the patient's response (e.g., change in HbA1c) results in a reward, guiding the learning process.
    \item The Q-values are updated iteratively based on the reward and the estimated value of subsequent states.
\end{itemize}

\subsection*{Results}
\begin{itemize}
    \item RL model tested on 60 unseen cases
    \item Recommended insulin dose interval included the physician-prescribed dose in 88\% of cases
    \item Results suggest the RL approach can effectively offer personalized treatment recommendations aligning with clinical decisions
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item \textbf{Limited dataset size:} Only 87 patients, which may limit generalizability
    \item \textbf{Discretization of variables:} Fineness of categories might affect the model's precision
    \item \textbf{Data quality and missing variables:} Not all potentially influential factors (like diet or stress) were included
    \item \textbf{Algorithm complexity:} RL models require careful tuning; real-world implementation must address issues like exploration vs. exploitation and patient safety
\end{itemize}

\subsection*{Future Directions}
\begin{itemize}
    \item Extend the model to include other types of insulin and medications
    \item Incorporate finer categories or continuous variables for more precise recommendations
    \item Validate with larger and more diverse datasets
    \item Explore application to other populations, such as patients with Type 2 Diabetes
    \item Implement real-time decision support in clinical settings
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item Limited patient sample size may not capture all variability in diabetes management
    \item Discretization may lead to loss of information that could be valuable for precise dosing
    \item No explicit mention of model validation techniques beyond testing on 60 cases
    \item Reward function description is brief; more detail would clarify alignment with clinical goals
\end{itemize}

% ============================== ARTICLE 8 =====================================
\section{Cardiovascular Diseases Prediction by Machine Learning Incorporation with Deep Learning}
\textbf{Article Reference:} \cite{article_8}

\subsection*{Overview}
The article discusses the increasing role of artificial intelligence (AI) in healthcare, particularly in predicting cardiovascular diseases (CVD). It highlights the growing prevalence of data from the Internet of Things (IoT) within healthcare systems, which can be leveraged to identify risk factors associated with CVD.

\subsection*{Dataset}
\begin{itemize}
    \item Heart dataset with 918 unique samples after removing duplicates
    \item Dataset comprises 11 features relevant for predicting CVD
\end{itemize}

\subsection*{Data Processing}
The study employed machine learning models to analyze the data received from Internet of Things (IoT) devices. Traditional machine learning algorithms were noted to have limitations in accuracy, which led to the exploration of advanced techniques for better predictions. A feature selection method using Tree SHAP was applied to identify significant features influencing CVD predictions. This method enhances the interpretability of the results by showing each feature's contribution to predictions.

\subsection*{Approach}
The researchers proposed a stacking fusion model-based classifier, which achieved an impressive accuracy of nearly 96\%. This model effectively combined the strengths of various algorithms, outperforming individual models in predicting high-risk individuals for CVD. They emphasized the limitations of traditional machine learning and the importance of large, diverse datasets for robust predictions.

\subsection*{Results}
The proposed stacking fusion model-based classifier demonstrated superior performance, achieving nearly 96\% accuracy. The model's performance remained stable after feature selection, with AUC values not significantly impacted by the removal of the Resting ECG feature.

\subsection*{Challenges}
One of the challenges noted in the study is the reliance on traditional machine learning algorithms, which may not adequately account for data variability, leading to lower accuracy in predictions. Additionally, the need for more extensive datasets from various medical institutions was emphasized.

\subsection*{Future Directions}
\begin{itemize}
    \item Incorporate additional deep learning techniques within IoT environments
    \item Enhance accuracy for identifying high-risk patients
    \item Implement early clinical interventions based on model predictions
    \item Develop more sophisticated models that can handle real-time streaming data
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item Need for broader dataset diversity incorporating various demographics and geographical locations
    \item More detailed explanation of the specific algorithms used in the stacking model would clarify their individual contributions
    \item Longitudinal studies would help assess the real-world effectiveness of the models
    \item The paper does not adequately address how data imbalance was handled
\end{itemize}

% ============================== ARTICLE 9 =====================================
\section{Optimizing Type 2 Diabetes Management: AI-Enhanced Time Series Analysis of Continuous Glucose Monitoring Data for Personalized Dietary Intervention}
\textbf{Article Reference:} \cite{article_9}

\subsection*{Overview}
This study proposes a method to optimize type 2 diabetes management using AI-enhanced time series analysis of continuous glucose monitoring (CGM) data. The goal is to enable personalized dietary interventions to improve patient outcomes.

\subsection*{Dataset}
\begin{itemize}
    \item Collected CGM data from 8 patients with type 2 diabetes.
    \item Data includes time-series blood glucose (BG) values.
\end{itemize}

\subsection*{Data Processing}
\begin{itemize}
    \item Removed NaN records to clean the data.
    \item Applied feature extraction and dimensionality reduction techniques.
    \item Split dataset into training (75\%) and testing (25\%) portions.
\end{itemize}

\subsection*{ML Approach}
\begin{itemize}
    \item Used regression models: XGBoost, SARIMA, Prophet.
    \item Evaluated using MAE, MSE, and R-squared (R²) metrics.
    \item Integrated dietary recommendations based on predicted BG levels.
\end{itemize}

\subsection*{Results}
\begin{itemize}
    \item XGBoost outperformed SARIMA and Prophet.
    \item Achieved high R² and low MAPE.
    \item Accurately predicted glucose fluctuations for timely intervention.
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item Limited dataset (only 8 patients) reduced model generalizability.
    \item Up to ±30-minute lag in CGM readings affected prediction accuracy.
\end{itemize}

\subsection*{Future Directions}
\begin{itemize}
    \item Expand dataset to improve training and validation.
    \item Enhance model with additional features and contextual data.
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item Promising approach, but small sample limits robustness.
    \item Time lag in CGM data must be addressed for better accuracy.
\end{itemize}

% ============================== ARTICLE 9 =====================================
\section{Optimizing Type 2 Diabetes Management: AI-Enhanced Time Series Analysis of Continuous Glucose Monitoring Data for Personalized Dietary Intervention}
\textbf{Article Reference:} \cite{article_9}

\subsection*{Overview}
This study proposes a method to optimize type 2 diabetes management using AI-enhanced time series analysis of continuous glucose monitoring (CGM) data. The goal is to enable personalized dietary interventions to improve patient outcomes.

\subsection*{Dataset}
\begin{itemize}
    \item Collected CGM data from 8 patients with type 2 diabetes.
    \item Data includes time-series blood glucose (BG) values.
\end{itemize}

\subsection*{Data Processing}
\begin{itemize}
    \item Removed NaN records to clean the data.
    \item Applied feature extraction and dimensionality reduction techniques.
    \item Split dataset into training (75\%) and testing (25\%) portions.
\end{itemize}

\subsection*{ML Approach}
\begin{itemize}
    \item Used regression models: XGBoost, SARIMA, Prophet.
    \item Evaluated using MAE, MSE, and R-squared (R²) metrics.
    \item Integrated dietary recommendations based on predicted BG levels.
\end{itemize}

\subsection*{Results}
\begin{itemize}
    \item XGBoost outperformed SARIMA and Prophet.
    \item Achieved high R² and low MAPE.
    \item Accurately predicted glucose fluctuations for timely intervention.
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item Limited dataset (only 8 patients) reduced model generalizability.
    \item Up to ±30-minute lag in CGM readings affected prediction accuracy.
\end{itemize}

\subsection*{Future Directions}
\begin{itemize}
    \item Expand dataset to improve training and validation.
    \item Enhance model with additional features and contextual data.
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item Promising approach, but small sample limits robustness.
    \item Time lag in CGM data must be addressed for better accuracy.
\end{itemize}

% ============================== ARTICLE 10 =====================================
\section{Deep Q-Network (DQN) Model for Disease Prediction Using Electronic Health Records (EHRs)}
\textbf{Article Reference:} \cite{article_10}

\subsection*{Overview}
The paper addresses the challenges of using deep learning models for disease prediction with EHRs, including lack of precision, ethical concerns, limitations of small datasets, complexity of data processing, and incompleteness of patient data. It proposes a deep Q-learning (DQL) model to enhance the accuracy and stability of predictions. The model integrates reinforcement learning with neural networks, utilizing the mapping capabilities of the Q-network. The proposed model is evaluated on the Heart Disease Dataset from the UCI Data Repository, demonstrating high accuracy (98\%) compared to other models.

\subsection*{Dataset}
\begin{itemize}
    \item The Heart Disease Dataset from the UCI Data Repository via Kaggle.
    \item Includes multivariate numerical data with 14 attributes (categorical, integer, and real data).
\end{itemize}

\subsection*{Data Processing}
\begin{itemize}
    \item The dataset was split into training (80\%) and test sets (20\%) using stratified splitting.
    \item Robust scaling was applied for feature scaling.
\end{itemize}

\subsection*{ML Approach}
\begin{itemize}
    \item The study uses a Deep Q-Network (DQN) model, which combines reinforcement learning with neural networks.
    \item This approach aims to address the limitations of traditional Q-learning and improve the accuracy and stability of disease predictions.
\end{itemize}

\subsection*{Implementation of Reinforcement Learning}
\begin{itemize}
    \item The model uses a "disease prediction game" environment.
    \item State: The state is represented by the samples from the EHR data.
    \item Action: Actions involve increasing, decreasing, or holding each feature.
    \item Reward: Positive rewards are given for accurate predictions, and negative rewards for inaccurate ones.
    \item Environment: The environment consists of sets of states (samples) and actions (feature adjustments).
\end{itemize}

\subsection*{Results}
\begin{itemize}
    \item The paper compares the Deep Q-Network (DQN) model with Logistic Regression, Decision Tree Classifier, Random Forest Classifier, and Gradient-Boosting Classifier.
\end{itemize}

Key Results:
\begin{itemize}
    \item The proposed EHR-DQN model achieved high accuracy (0.9841) and a low mean squared error (MSE) of 0.0001.
    \item The Decision Tree and Gradient-Boosting Classifiers also performed well, with perfect precision, recall, and F1 scores.
    \item The Random Forest model showed a balance of high accuracy (0.9783) and a minimal MSE of 0.
    \item Logistic Regression had the lowest performance, with an accuracy of 0.8424 and a higher MSE of 0.1576.
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item Data-related issues: digitization, consolidation, and availability of health records.
    \item Privacy and legal concerns with patient data handling.
    \item Patient-related difficulties: decision-making errors, treatment errors, and data inconsistencies.
    \item Technical challenges: data integration across systems, ensuring patient security.
    \item Interpretability: "black box" nature of complex AI models limits transparency.
    \item Resource limitations: computational resources and expertise needed for implementation.
\end{itemize}

\subsection*{Future Directions}
\begin{itemize}
    \item Expand the dataset size to better train deep reinforcement learning models.
    \item Integrate additional contextual features to improve prediction accuracy.
    \item Develop more transparent models to address interpretability concerns.
    \item Create more standardized methods for validating healthcare AI systems.
    \item Improve integration with clinical workflows for practical implementation.
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item The paper emphasizes the high accuracy of the proposed model but also points out that the dataset used has only thousands of samples. The DQN algorithm typically requires a large number of training samples (millions) to achieve optimal performance.
    \item The paper acknowledges the "black box" nature of many AI algorithms and the resulting lack of interpretability, which can hinder trust and adoption in healthcare.
\end{itemize}

% ============================== ARTICLE 11 =====================================
\section{A Reinforcement Learning Model for AI-Based Decision Support in Skin Cancer}
\textbf{Article Reference:} \cite{article_11}

\subsection*{Overview}
\begin{itemize}
    \item The article presents a reinforcement learning (RL) model designed to enhance decision support in skin cancer diagnosis.
    \item It compares the effectiveness of RL with supervised learning (SL) methods, emphasizing the potential of RL in optimizing management decisions.
\end{itemize}

\subsection*{Dataset}
\begin{itemize}
    \item They utilized the publicly available HAM10000 dataset, a comprehensive collection of dermatoscopic images of skin lesions.
    \item This dataset contains over 10,000 images across seven diagnostic categories of skin lesions.
\end{itemize}

\subsection*{Data Processing}
\begin{itemize}
    \item For patient-centered scenarios, input vectors were normalized by dividing position-wise by the average across all lesion vectors of the same patient.
    \item This normalization was crucial for processing multiple lesions from the same patient effectively.
    \item Feature extraction was performed using convolutional neural networks pre-trained on the dataset.
\end{itemize}

\subsection*{ML Approach}
\begin{itemize}
    \item Supervised Learning (SL): A convolutional neural network was fine-tuned for classifying seven categories of skin lesions.
    \item Reinforcement Learning (RL): A deep Q-learning model was developed using a multilayer perceptron that processed feature vectors derived from the SL model.
    \item They also implemented a threshold-based approach for comparison.
\end{itemize}

\subsection*{Implementation of Reinforcement Learning}
\begin{itemize}
    \item States: One-dimensional vectors representing features of skin lesions.
    \item Actions: Management strategies including excision, short-term follow-up, and regular surveillance.
    \item Rewards: Defined based on diagnosis outcomes and management decisions, optimizing for both clinical efficacy and resource utilization.
    \item Learning: The model used experience replay and target networks to stabilize learning.
\end{itemize}

\subsection*{Results}
\begin{itemize}
    \item The RL method and threshold method both improved management decisions compared to the naïve SL model.
    \item Both approaches optimized operating points on decision curves, enhancing diagnostic accuracy.
    \item The RL model demonstrated superior performance in balancing sensitivity and specificity.
    \item The study showed potential for reducing unnecessary excisions while maintaining high detection rates.
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item RL models require more complex retraining compared to simpler threshold approaches.
    \item Integration into clinical workflows presents practical implementation barriers.
    \item Limited consideration of patient preferences in the current model design.
    \item Lack of longitudinal data to validate long-term decision outcomes.
\end{itemize}

\subsection*{Future Directions}
\begin{itemize}
    \item Development of reward tables incorporating both physician and patient preferences.
    \item Enhancement of shared decision-making tools combining AI recommendations with clinical expertise.
    \item Integration of additional clinical parameters beyond image data.
    \item Validation in prospective clinical trials to assess real-world impact.
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item It focuses primarily on physician preferences, potentially neglecting patient-centered care principles.
    \item Limited dataset diversity may restrict generalizability across different patient populations.
    \item The complexity of RL models may limit practical implementation in resource-constrained settings.
    \item Further validation is needed to demonstrate clinical utility beyond technical performance metrics.
\end{itemize}

% ============================== ARTICLE 12 =====================================
\section{Reinforcement Learning Using Deep Q Networks and Q-Learning Accurately Localizes Brain Tumors on MRI with Very Small Training Sets}
\textbf{Article Reference:} \cite{article_12}

\subsection*{Overview}
This study applies reinforcement learning (RL), specifically Deep Q Networks (DQN), to accurately localize brain tumors in MRI scans. It addresses the limitations of traditional supervised learning methods, particularly the dependence on large annotated datasets. The authors demonstrate that RL can achieve high performance even with minimal training data.

\subsection*{Dataset}
The dataset used comprises 2D slices from the 2014 BraTS (Brain Tumor Segmentation) challenge dataset. These are T1-weighted contrast-enhanced MRI images. The training set included 30 images, with another 30 images used for testing.

\subsection*{Data Processing}
\begin{itemize}
    \item 2D slices were extracted and the image space was divided into a grid.
    \item Each agent operates within a 60 × 60 pixel block.
    \item No data augmentation was applied to keep training consistent with the original dataset.
\end{itemize}

\subsection*{Implementation of Reinforcement Learning}
\begin{itemize}
    \item \textbf{Environment:} Modeled as a gridworld over MRI images.
    \item \textbf{States:} Represented by the agent's position in the image grid.
    \item \textbf{Actions:} The agent can move down, move right, or stay in place.
    \item \textbf{Rewards:} Positive rewards for entering tumor regions, penalties for remaining idle outside the tumor area.
    \item The DQN used experience replay and a target network to stabilize learning.
\end{itemize}

\subsection*{Results}
\begin{itemize}
    \item The DQN achieved an average localization accuracy of 70\% over the last 20 episodes.
    \item This significantly outperformed a supervised deep learning approach, which achieved only 11\% accuracy.
    \item Results demonstrate RL’s superiority with small datasets in this context.
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item The reliance on small datasets may limit generalizability.
    \item High computational cost of RL may pose integration challenges in real-time clinical settings.
\end{itemize}

\subsection*{Future Directions}
\begin{itemize}
    \item Extend the RL model to handle full 3D MRI volumes.
    \item Compare performance with other RL strategies such as policy-gradient methods.
    \item Optimize training and inference to improve clinical applicability.
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item The model's performance with small data is promising but needs validation on larger, more diverse datasets.
    \item No integration of clinical context or physician-in-the-loop evaluation.
    \item Despite excellent performance metrics, interpretability and ease of integration in hospitals remain unresolved.
\end{itemize}

% ============================== ARTICLE 13 =====================================
\section{Deep Reinforcement Learning and Simulation as a Path Toward Precision Medicine}
\textbf{Article Reference:} \cite{article_13}

\subsection*{Overview}
The paper explores the application of deep reinforcement learning (DRL) to develop personalized treatment strategies for sepsis, a severe condition caused by the body's dysregulated immune response to infection. The authors propose a novel approach that leverages simulation to identify effective multicytokine therapies tailored to individual patients based on their systemic measurements.

\subsection*{Dataset}
\begin{itemize}
    \item The study used an Innate Immune Response Agent-Based Model (IIRABM) to simulate sepsis progression.
    \item A set of 500 simulated patients with diverse genetic and physiological parameters was generated.
    \item No real-world patient data was used directly, as the approach relies on in silico modeling.
\end{itemize}

\subsection*{Data Processing}
\begin{itemize}
    \item Simulated patient data included various systemic measurements relevant to sepsis.
    \item Continuous monitoring of cytokine levels, immune cell populations, and tissue damage metrics.
    \item Patient states were represented as high-dimensional continuous variables.
\end{itemize}

\subsection*{Implementation of Reinforcement Learning}
\begin{itemize}
    \item \textbf{Environment:} Simulated sepsis progression using an agent-based model (ABM) of the innate immune response to infection.
    \item \textbf{States:} High-dimensional and continuous state space representing patient condition through various health metrics and systemic measurements.
    \item \textbf{Actions:} Continuous action space for administering multicytokine therapies with varying dosages.
    \item \textbf{Rewards:} Terminal rewards of +250 for healed patients and -250 for death cases, with intermediate rewards based on tissue damage changes and an L1 penalty to encourage conservative treatments.
    \item \textbf{Learning Process:} Episodes of patient treatment where the agent learns to refine its policy to maximize cumulative rewards.
\end{itemize}

\subsection*{Results}
\begin{itemize}
    \item DRL-based approach achieved significant reduction in mortality rates across 500 simulated patients.
    \item Demonstrated ability to learn complex therapeutic strategies adaptive to individual disease progression.
    \item Outperformed conventional standalone antibiotic therapy in simulations.
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item Ethical concerns related to exploring suboptimal treatments in real patients.
    \item Complexity of dynamic multicytokine mediation requiring extensive exploration of treatment strategies.
    \item Need for advanced strategies to achieve lower mortality rates across diverse patient simulations.
\end{itemize}

\subsection*{Future Directions}
\begin{itemize}
    \item Development of measurement technologies informed by simulation findings.
    \item Identification of biological targets for drug development.
    \item Design of clinical trials for adaptive personalized therapies.
    \item Expansion of simulation and DRL approach to other medical conditions beyond sepsis.
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item Heavy reliance on simulation may not fully capture real-world clinical complexities.
    \item Ethical implications of testing derived treatment strategies remain significant.
    \item Clinical validation through trials needed to confirm applicability in real-world settings.
    \item Gap between simulation-derived policies and practical clinical implementation.
\end{itemize}

% ============================== ARTICLE 14 =====================================
\section{PrescDRL: Deep Reinforcement Learning for Herbal Prescription Planning in Treatment of Chronic Diseases}
\textbf{Article Reference:} \cite{article_14}

\subsection*{Overview}
This paper presents PrescDRL, a novel framework that applies deep reinforcement learning to optimize herbal prescriptions in Traditional Chinese Medicine (TCM) for the treatment of chronic diseases. Instead of focusing on immediate treatment effects, the approach emphasizes long-term patient outcomes through sequential treatment strategies, specifically focusing on diabetes as a case study.

\subsection*{Dataset}
\begin{itemize}
    \item A custom high-quality benchmark dataset for sequential diagnosis and treatment of diabetes.
    \item Data includes patient medical records and treatment histories specifically curated for evaluating the PrescDRL model.
    \item Dataset constructed to enable comparison between the model's recommendations and traditional treatment methods.
\end{itemize}

\subsection*{Data Processing}
\begin{itemize}
    \item Cleaning and normalization of patient medical records.
    \item Standardization of herbal prescription information.
    \item Conversion of medical data into appropriate state representations for the RL framework.
    \item Feature extraction from patient medical histories to capture relevant health indicators.
\end{itemize}

\subsection*{Implementation of Reinforcement Learning}
\begin{itemize}
    \item \textbf{State:} Representation of patient health status derived from medical records and treatment history.
    \item \textbf{Actions:} Selection from 30 well-tuned herbal prescription candidates (HPCs).
    \item \textbf{Reward:} Designed to maximize treatment efficacy while ensuring safety and avoiding side effects.
    \item \textbf{Environment:} Consists of patient medical history and the set of possible herbal prescriptions.
    \item \textbf{Learning Process:} Deep RL techniques to optimize prescription sequences for long-term health improvements.
\end{itemize}

\subsection*{Results}
\begin{itemize}
    \item 117\% and 153\% improvement in single-step rewards compared to traditional doctor prescriptions.
    \item 40.5\% increase in precision for prescription prediction.
    \item 63\% increase in recall for prescription recommendations.
    \item Demonstrated superior performance in generating sequential treatment strategies for chronic conditions.
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item Ensuring generalizability across diverse patient populations.
    \item Balancing immediate treatment effects with long-term health outcomes.
    \item Integration of the model recommendations into existing clinical workflows.
    \item Limited availability of comprehensive, high-quality TCM treatment data.
\end{itemize}

\subsection*{Future Directions}
\begin{itemize}
    \item Expansion of the dataset to include additional chronic diseases beyond diabetes.
    \item Refinement of the model to incorporate more nuanced patient characteristics.
    \item Real-world clinical validation studies to assess practical applicability.
    \item Development of interpretable models to enhance physician trust and adoption.
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item The study would benefit from more detailed exploration of dataset characteristics.
    \item Further validation in real-world clinical settings is needed to establish practical efficacy.
    \item Limited information on specific preprocessing steps may affect reproducibility.
    \item Integration challenges with conventional medical practices need addressing for broader adoption.
\end{itemize}

% ============================== ARTICLE 15 =====================================
\section{Deep Reinforcement Learning for Multi-Class Imbalanced Training: Applications in Healthcare}
\textbf{Article Reference:} \cite{article_15}

\subsection*{Overview}
This paper presents a novel deep reinforcement learning framework designed to address multi-class imbalanced classification problems in healthcare settings. Unlike traditional methods that often underperform with imbalanced data, this approach leverages reinforcement learning to improve the prediction of minority classes without compromising performance on majority classes, which is particularly valuable in clinical contexts where rare conditions must be accurately identified.

\subsection*{Dataset}
\begin{itemize}
    \item Real-world clinical case studies exhibiting significant class imbalance.
    \item Datasets containing rare events among numerous majority class cases.
    \item Multiple validation datasets from different hospital trusts for out-of-sample testing.
    \item Imbalance ratios extending beyond the previously studied threshold of 10\%.
\end{itemize}

\subsection*{Data Processing}
\begin{itemize}
    \item Feature selection and extraction from clinical data.
    \item Normalization and standardization of input variables.
    \item Structuring of data for sequential decision-making framework.
    \item Preparation of cross-validation sets for robust evaluation.
\end{itemize}

\subsection*{Implementation of Reinforcement Learning}
\begin{itemize}
    \item \textbf{State (s):} Representation of the current data point being classified, including its features and context.
    \item \textbf{Action (a):} Possible class assignments that the model can choose from.
    \item \textbf{Reward (r):} Custom reward function designed to incentivize correct classifications, with higher rewards for accurately identifying minority classes.
    \item \textbf{Policy:} The strategy guiding the agent's decision-making process based on observed states.
    \item \textbf{Environment (p):} The classification task context, including the dataset characteristics.
    \item \textbf{Architecture:} Combined dueling and double deep Q-learning architectures to enhance state-value function learning efficiency.
\end{itemize}

\subsection*{Results}
\begin{itemize}
    \item Outperformed existing state-of-the-art imbalanced learning methods across multiple metrics.
    \item Significantly improved sensitivity for minority classes while maintaining high specificity.
    \item Demonstrated consistent performance across various out-of-sample validation datasets.
    \item Achieved more balanced classification performance compared to traditional machine learning approaches.
    \item Successfully generalized to data from different hospital trusts, indicating robust real-world applicability.
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item Addressing extremely imbalanced datasets where rare events may represent less than 0.1\% of cases.
    \item Computational complexity of training reinforcement learning models on large clinical datasets.
    \item Potential for reward function design to introduce unintended biases in model behavior.
    \item Integration challenges with existing clinical decision support systems.
    \item Interpretability concerns when applying complex RL models in healthcare settings.
\end{itemize}

\subsection*{Future Directions}
\begin{itemize}
    \item Expansion to handle even more complex multi-class imbalance scenarios.
    \item Exploration of additional RL techniques to further enhance performance.
    \item Development of more sophisticated reward mechanisms that incorporate clinical domain knowledge.
    \item Investigation of model explainability to increase trust among healthcare practitioners.
    \item Implementation and testing in real-time clinical decision-making environments.
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item Limited evaluation on specific datasets may not fully represent all clinical scenarios.
    \item Potential biases from the sample populations used in the study.
    \item Real-time applicability in clinical settings requires further investigation.
    \item Trade-offs between model complexity and interpretability need more thorough exploration.
    \item The adaptability to various clinical contexts beyond those studied remains to be fully evaluated.
\end{itemize}
% ============================== ARTICLE 16 =====================================
\section{Deep Attention Q-Network for Personalized Treatment Recommendation}
\textbf{Article Reference:} \cite{article_16}

\subsection*{Overview}
The paper  addresses the challenge of tailoring treatment for critically ill patients using reinforcement learning (RL). Existing methods often rely solely on a patient's current physiological state, which may not fully represent their overall health. To overcome this, the authors propose a novel approach that incorporates historical observations, using the Transformer architecture within a deep RL framework to improve treatment recommendations.

\subsection*{Dataset}
\begin{itemize}
    \item Real-world clinical datasets for:
    \begin{itemize}
        \item Sepsis patients
        \item Acute hypotension patients
    \end{itemize}
    \item Used for evaluating the effectiveness of the proposed RL-based method in real clinical settings.
\end{itemize}

\subsection*{Data Processing}
\begin{itemize}
    \item Although specific preprocessing details are not exhaustively detailed, standard clinical data preparation techniques are implied:
    \begin{itemize}
        \item Data cleaning and handling of missing values.
        \item Feature normalization to ensure model stability.
        \item Temporal alignment of patient history for sequential modeling.
    \end{itemize}
\end{itemize}

\subsection*{Implementation of Reinforcement Learning}
\begin{itemize}
    \item \textbf{State (s):} Includes both current and past observations of the patient's health status to enhance context-awareness.
    \item \textbf{Action (a):} Represents the set of possible treatment decisions, such as medication dosages or intervention timings.
    \item \textbf{Reward (r):} Guided by clinical insights, aiming to optimize patient outcomes based on treatment efficacy.
    \item \textbf{Policy:} Learned policy maximizes expected rewards by considering prior observations indicative of declining health.
    \item \textbf{Environment (p):} The patient's evolving health condition within a clinical setting where the agent receives feedback.
    \item \textbf{Architecture:} Deep Attention Q-Network integrating Transformer modules for capturing long-term dependencies in patient data.
\end{itemize}

\subsection*{Results}
\begin{itemize}
    \item The proposed model outperformed traditional treatment recommendation methods, including:
    \begin{itemize}
        \item LSTM-based models (memorization-based).
        \item RL models that ignored historical observations.
    \end{itemize}
    \item Off-policy evaluation showed better expected rewards than clinician policies and random baselines.
    \item Demonstrated stronger alignment with optimal treatment outcomes by leveraging temporal patient information.
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item Evaluation of RL models using offline data sampled from clinician-led decisions.
    \item Complexity of deep attention models makes real-time deployment difficult.
    \item Potential for bias due to reliance on historical clinical datasets.
    \item Necessity for interpretability and trust in clinical applications.
\end{itemize}

\subsection*{Future Directions}
\begin{itemize}
    \item Enhancing model interpretability to improve clinician acceptance.
    \item Refinement of reward functions based on additional clinical feedback.
    \item Exploration of hybrid architectures to balance complexity and performance.
    \item Real-time deployment trials in clinical decision-making environments.
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item Dependence on historical data may introduce systemic biases not reflective of current populations.
    \item Model complexity could hinder adoption in clinical workflows.
    \item Need for validation across broader and more diverse clinical settings.
    \item Interpretability and transparency remain challenges in deep RL models used in healthcare.
\end{itemize}
% ============================== ARTICLE 17 =====================================
\section{Deep Q-Learning for Treatment Selection in Oropharyngeal Squamous Cell Carcinoma}
\textbf{Article Reference:} \cite{article_17}

\subsection*{Overview}
This paper explores the use of Deep Q-Learning (DQL) to optimize sequential treatment decisions for patients with oropharyngeal squamous cell carcinoma. It introduces a dual digital twin framework — one representing the patient and the other representing the physician — to personalize treatments based on survival and toxicity outcomes.

\subsection*{Dataset}
\begin{itemize}
    \item 536 patient records from MD Anderson Cancer Center (2005–2013).
    \item Includes comprehensive patient histories and three-step sequential treatment decisions.
    \item Radiomics features derived from segmented primary tumor volumes were also integrated.
    \item Data was split: 75\% (402 patients) for training and 25\% (134 patients) for evaluation.
\end{itemize}

\subsection*{Preprocessing of Data}
\begin{itemize}
    \item Random data split into training and evaluation sets.
    \item Some models trained with radiomics features to assess added predictive value.
\end{itemize}

\subsection*{Approach Used}
\begin{itemize}
    \item A 3-step Markov Decision Process (MDP) framework was used.
    \item Deep Q-Learning was applied to learn a treatment policy maximizing a linear combination of outcomes (e.g., survival and toxicity reduction).
\end{itemize}

\subsection*{Implementation of Reinforcement Learning}
\begin{itemize}
    \item \textbf{States (s):} Patient health conditions at each treatment decision point.
    \item \textbf{Actions (a):} Treatment options chosen at each of the three decision stages.
    \item \textbf{Rewards (r):} Based on survival and treatment-related toxicity using a defined reward function.
    \item \textbf{Environment (p):} The clinical treatment trajectory where decisions influence future patient state transitions.
\end{itemize}

\subsection*{Results}
\begin{itemize}
    \item Achieved a mean accuracy of 87.35\% and median accuracy of 90.85\% in predicting treatment outcomes.
    \item Improved predicted survival rate by 3.73\% and reduced predicted dysphagia rate by 0.75\% over clinician decisions.
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item High-dimensional state space required extensive data to accurately compute rewards.
    \item Managing stochastic nature of outcomes posed difficulty for consistent policy optimization.
\end{itemize}

\subsection*{Future Directions}
\begin{itemize}
    \item Integration of more radiomics features for enhanced prediction.
    \item Expansion to include larger and more diverse patient populations.
    \item Exploration of alternative architectures for real-time deployment.
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item Reliance on historical clinical data may reduce generalizability.
    \item High computational requirements for training and bootstrapping limit clinical scalability.
    \item Encouraging results indicate strong potential for real-world impact pending further validation.
\end{itemize}
% ============================== ARTICLE 18 =====================================
\section{Personalized Multimorbidity Management in Type 2 Diabetes Using Reinforcement Learning}
\textbf{Article Reference:} \cite{article_18}

\subsection*{Overview}
This paper introduces an AI-based reinforcement learning (RL) algorithm for personalized management of Type 2 Diabetes Mellitus (T2DM) and its comorbidities. The algorithm dynamically recommends individualized treatment regimens using longitudinal electronic health records (EHRs) to improve health outcomes including glycemic control, blood pressure (BP), and cardiovascular disease (CVD) risk.

\subsection*{Dataset}
\begin{itemize}
    \item Retrospective cohort of 16,665 patients from New York University Langone Health (NYULH) ambulatory care EHRs.
    \item Data spans from 2009 to 2017.
    \item Inclusion criteria involved multiple encounters with T2DM-related ICD-10 codes or abnormal hemoglobin A1c levels.
\end{itemize}

\subsection*{Preprocessing of Data}
\begin{itemize}
    \item Patients seen only for consultation or emergency visits were excluded to ensure longitudinal data quality.
    \item Final dataset split: 60\% for training and 40\% for testing.
\end{itemize}

\subsection*{Approach Used}
\begin{itemize}
    \item Developed three independent RL models: RL-glycemia, RL-BP, and RL-CVD.
    \item These were integrated into a multimorbidity RL model to optimize overall patient outcomes across the three conditions.
\end{itemize}

\subsection*{Implementation of Reinforcement Learning}
\begin{itemize}
    \item \textbf{States (s):} Include patient demographics, lab test results, and past treatment history at each encounter.
    \item \textbf{Actions (a):} Represent the selected treatment regimens (pharmacologic subclasses or combinations).
    \item \textbf{Rewards (r):} Defined by achieving target health outcomes (e.g., A1c < 7\%, BP within range, low CVD risk).
    \item \textbf{Environment (p):} Simulated patient trajectory over time based on health states and treatments.
\end{itemize}

\subsection*{Results}
\begin{itemize}
    \item High concordance with clinician prescriptions: 86.1\% (glycemia), 82.9\% (BP), and 98.4\% (CVD).
    \item In cases of disagreement, the RL model's recommendations were associated with better clinical outcomes.
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item The reward function lacked important biomarkers like creatinine, limiting clinical realism.
    \item The study population may not be generalizable to the broader U.S. T2DM population.
    \item Balancing clinical domain knowledge with algorithmic optimization remains a key challenge.
\end{itemize}

\subsection*{Future Directions}
\begin{itemize}
    \item Conduct randomized clinical trials to compare RL-guided and clinician-guided treatments.
    \item Expand reward functions to include adverse events and broader health metrics.
    \item Test the approach across more diverse and representative patient populations.
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item While the RL algorithm shows strong potential in managing multimorbidity in T2DM, the reliance on historical EHRs may introduce systemic biases.
    \item The algorithm's performance may degrade in underrepresented demographics.
    \item More robust clinical integration and validation are required before real-world adoption.
\end{itemize}

% ============================== ARTICLE 19 =====================================
\section{Deep Reinforcement Learning for Personalized Treatment Recommendation}
\textbf{Article Reference:} \cite{article_19}

\subsection*{Overview}
This paper proposes a deep reinforcement learning (DRL) approach, called PPORank, to enhance precision medicine through personalized treatment recommendation, specifically in the context of cancer therapy. The method formulates treatment ranking as a sequential decision-making problem to improve patient-specific outcomes.

\subsection*{Datasets Used}
\begin{itemize}
    \item \textbf{Immunohistochemistry Annotations:} Includes 163 HER2-positive and 116 triple-negative breast cancer (TNBC) patients.
    \item \textbf{The Cancer Genome Atlas (TCGA):} Used for generalizing findings from cell line data to real-world patient data.
    \item \textbf{GDSC Gene Expression Data:} Harmonized with RNA-seq data from 1080 patients for analysis consistency.
\end{itemize}

\subsection*{Data Preprocessing}
\begin{itemize}
    \item Excluded drug samples lacking PubChem IDs.
    \item Harmonized gene expression datasets across sources.
    \item Final dataset contained 223 drugs after filtering.
\end{itemize}

\subsection*{Approach Used}
\begin{itemize}
    \item Introduces PPORank, a DRL model utilizing a deep neural network to learn state representations from heterogeneous data.
    \item Employs a model-free actor-critic framework, optimized via Proximal Policy Optimization (PPO).
    \item Optimizes the non-differentiable ranking metric NDCG (Normalized Discounted Cumulative Gain) through policy gradients.
\end{itemize}

\subsection*{Results}
\begin{itemize}
    \item PPORank outperforms state-of-the-art supervised learning approaches in cancer drug ranking tasks.
    \item Demonstrated stability and sample efficiency on high-dimensional screening datasets.
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item DRL and deep learning are inherently data-hungry, posing challenges for biomedical applications with limited data.
    \item Interpretability of deep learning remains a barrier to clinical adoption.
    \item Adapting RL to account for safety, risk, and limited samples is an ongoing research challenge.
\end{itemize}

\subsection*{Future Directions}
\begin{itemize}
    \item Incorporating active learning to improve interaction with dynamic patient data.
    \item Enhancing the robustness of DRL models by integrating diverse biomedical data sources.
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item Although PPORank shows promising results, its reliance on large datasets may hinder its real-world usability in data-scarce settings.
    \item Future success will depend on improving data efficiency and model transparency for practical clinical deployment.
\end{itemize}

% ============================== ARTICLE 20 =====================================
\section{AI-Based COVID-19 Detection Using CT Imaging}
\textbf{Article Reference:} \cite{article_20}

\subsection*{Overview}
The article presents a deep learning algorithm developed to screen for COVID-19 using CT images, motivated by the limitations of traditional pathogenic testing methods (e.g., nucleic acid testing), which may yield false negatives. The main objective is to provide rapid and accurate diagnoses to help mitigate the spread of the virus.

\subsection*{Data Used}
\begin{itemize}
    \item A total of 1,065 CT images were collected.
    \item Included 180 cases of typical viral pneumonia and 79 confirmed COVID-19 cases from three hospitals.
    \item An additional 15 COVID-19 cases were added where initial nucleic acid tests were negative.
\end{itemize}

\subsection*{Data Preprocessing}
\begin{itemize}
    \item All images were resized to 299 × 299 pixels for input consistency.
    \item Lung regions were manually delineated to focus on regions of interest (ROIs), improving model focus.
    \item Images were converted to a virtual RGB format to match the input requirements of the modified inception model.
\end{itemize}

\subsection*{Approach Used}
\begin{itemize}
    \item A transfer learning strategy was employed using a modified inception model, referred to as M-inception.
    \item Only the customized layers were trained, leveraging pre-trained weights to reduce overfitting and training time.
    \item The architecture aimed to classify CT images to distinguish between COVID-19 and other viral pneumonias.
\end{itemize}

\subsection*{Results}
\begin{itemize}
    \item Internal validation accuracy was 89.5\% (Specificity: 0.88, Sensitivity: 0.87).
    \item External test accuracy was 79.3\% (Specificity: 0.83, Sensitivity: 0.67).
    \item In 54 cases where nucleic acid tests were initially negative, the model correctly predicted 46 cases, achieving an accuracy of 85.2\%.
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item CT images often include irrelevant elements, complicating automated diagnosis.
    \item A relatively small training dataset may reduce generalizability and increase model bias.
    \item Low signal-to-noise ratio and data heterogeneity pose significant hurdles in applying deep learning in clinical diagnostics.
\end{itemize}

\subsection*{Future Directions}
\begin{itemize}
    \item Expand the dataset to cover a larger number of COVID-19 cases across various pathological stages.
    \item Optimize the model's robustness, accuracy, and reliability by including diverse imaging scenarios.
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item The study provides a compelling proof-of-concept for AI-based diagnostics, but its effectiveness is limited by dataset size.
    \item Future work should emphasize external validation and distinguishability from other respiratory diseases.
\end{itemize}



% ============================== ARTICLE 21 =====================================
\section{Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning}
\textbf{Article Reference:} \cite{article_21}

\subsection*{Overview}
This study presents the development of an artificial intelligence (AI) system based on transfer learning to diagnose medical conditions using medical imaging. The authors focus on the classification of images for macular degeneration, diabetic retinopathy, and pneumonia from chest X-rays. The aim is to demonstrate that AI can improve diagnostic accuracy and speed, often matching or exceeding human performance.

\subsection*{Data Used}
\begin{itemize}
    \item \textbf{Optical Coherence Tomography (OCT)}: Out of 207,130 collected OCT images, 108,312 high-quality images were retained after a quality review for training.
    \item \textbf{Chest X-ray Images}: A dataset consisting of 5,232 pediatric chest X-rays was used to train the model for pneumonia classification, with an additional 624 patient images used for testing.
\end{itemize}

\subsection*{Data Preprocessing}
\begin{itemize}
    \item Quality control to filter OCT images.
    \item Categorization of images according to medical diagnosis to facilitate supervised learning.
\end{itemize}

\subsection*{Approach}
\begin{itemize}
    \item The model utilizes a transfer learning strategy, initializing from pre-trained convolutional neural networks to boost performance despite the relatively small dataset size.
    \item Classification tasks included urgent referral detection for conditions like choroidal neovascularization and diabetic macular edema.
    \item The approach also focused on distinguishing between bacterial and viral pneumonia on pediatric chest X-rays.
\end{itemize}

\subsection*{Results}
\begin{itemize}
    \item \textbf{96.6\% accuracy} in OCT image classification.
    \item \textbf{92.8\% accuracy} in pneumonia detection from chest X-rays.
    \item Performance was comparable to that of experienced clinicians, highlighting the potential of AI in supporting medical decision-making.
\end{itemize}

\subsection*{Challenges}
\begin{itemize}
    \item Difficulty in obtaining large and diverse labeled medical datasets.
    \item Clinical interpretability of the AI decisions, a common barrier in the adoption of deep learning in healthcare.
\end{itemize}

\subsection*{Future Directions}
\begin{itemize}
    \item Expanding the dataset with images from multiple imaging devices and settings to improve model generalizability.
    \item Extending the transfer learning approach to other imaging modalities beyond OCT and X-ray.
\end{itemize}

\subsection*{Critique}
\begin{itemize}
    \item While the approach is promising and the results impressive, the generalizability of the model remains a concern due to dataset limitations.
    \item Further validation with larger, more heterogeneous datasets is necessary.
    \item The open release of data and code is a notable contribution, encouraging reproducibility and further research in AI for medical imaging.
\end{itemize}

% ============================== COMPARISON TABLE ==============================
\section{Comparison of the Solutions}
\begin{table}[htbp]
\begin{adjustwidth}{-2cm}{-2cm}
\centering
\scriptsize
\begin{tabular}{|p{1.5cm}|p{2.5cm}|p{3cm}|p{3.5cm}|p{2.5cm}|p{2.5cm}|}
\hline
\textbf{Work} & \textbf{Disease/Domain} & \textbf{Dataset} & \textbf{Data Processing} & \textbf{Approach} & \textbf{Results} \\
\hline
\cite{article_1} & Epilepsy & Phase III (235) + Validation (47) patients & Clinical + WGS feature extraction (e.g., SV2A), mutational scores, PRS & Gradient-Boosted Decision Trees & AUC: 0.76 (train), 0.75 (validation) \\
\hline
\cite{article_2} & Diabetes Prediction & Pima Indian (768) + RTML (203) records & Imputation, ADASYN, Mutual Info, Holdout Validation & XGBoost + Ensemble Methods (voting, bagging) & AUC: 0.84, Accuracy: 81\%, F1 Score: 0.81 \\
\hline
\cite{article_3} & Alzheimer's Disease & Wearable sensors and motion capture data & Normalization, median imputation, SMOTE, RFE, correlation analysis & Hybrid CNN-RNN (LSTM) & Accuracy: 93\%, Precision: 92\%, Recall: 91\%, F1-Score: 91.5\%, AUC-ROC: 95\% \\
\hline
\cite{article_4} & Diabetes & ECG recordings (71 datasets) & Pan-Tompkins for QRS detection & CNN-LSTM + SVM & Accuracy: 95.7\% \\
\hline
\cite{article_5} & Heart Disease & UCI Cleveland Heart Disease dataset & Feature selection, data augmentation, reinforcement-based iteration & RL + Data Augmentation & Accuracy: 94\% \\
\hline
\cite{article_6} & Cardiovascular Disease & PCG datasets (GitHub + PhysioNet) & Minimal preprocessing on raw heart sound signals & Lightweight CRNN (CardioXNet) with dual learning (representation + sequence residual) & Accuracy: 99.6\% (GitHub), 86.57\% (PhysioNet), 0.67M params, $\sim$54.6ms latency \\
\hline
\cite{article_7} & Type 1 Diabetes & Clinical data from 87 patients (MGH, 2003–2013) & Discretization of HbA1c, BMI, activity level, alcohol usage into states & Q-Learning (model-free RL) for insulin dosing & 88\% RL suggestions matched physician dose \\
\hline
\cite{article_8} & Cardiovascular Disease & Heart dataset (918 samples, 11 features) & Duplicate removal, Tree SHAP feature selection & Stacking fusion model with IoT-enhanced data inputs & Accuracy: 96\%, Stable AUC after feature pruning \\
\hline
\cite{article_9} & Type 2 Diabetes & CGM data from 8 patients & NaN removal, feature extraction, dimensionality reduction, 75/25 train-test split & XGBoost, SARIMA, Prophet regression for BG prediction + dietary recommendations & XGBoost: High R², low MAPE, effective BG prediction for personalized intervention \\
\hline
\cite{article_10} & Heart Disease & UCI Heart Disease Dataset via Kaggle (14 attributes) & Stratified 80/20 train-test split with robust scaling & Deep Q-Network (DQN) with reinforcement learning & Accuracy: 98.41\%, MSE: 0.0001, outperformed traditional classifiers \\
\hline
\cite{article_11} & Skin Cancer & HAM10000 dataset (10,000+ dermatoscopic images) & Feature extraction via CNN, patient-level normalization for multiple lesions & Comparative RL (Deep Q-learning) vs SL (CNN) for decision support & Improved diagnostic and management decisions, optimal operating points on decision curves \\
\hline
\cite{article_12} & Brain Tumor Localization & BraTS 2014 (T1-weighted contrast-enhanced MRI, 60 images total) & Grid-based image division, no augmentation, 60x60 pixel block navigation & Deep Q-Network (DQN) with position-based rewards in gridworld & 70\% accuracy vs 11\% for SL; high performance on small training data \\
\hline
\cite{article_13} & Sepsis Treatment & 500 simulated patients using IIRABM & Continuous monitoring of cytokine levels, immune cell populations, and tissue damage metrics & Deep Reinforcement Learning with simulation-based approach for multicytokine therapy & Significant mortality reduction in simulated patients compared to standard antibiotic therapy \\
\hline
\cite{article_14} & Diabetes Treatment (TCM) & Custom benchmark dataset for sequential diagnosis and treatment of diabetes & Cleaning, normalization of medical records, standardization of herbal prescriptions & PrescDRL: Deep RL for optimizing herbal prescription sequences & 117-153\% improvement in single-step rewards, 40.5\% increase in precision, 63\% increase in recall vs. traditional prescriptions \\
\hline
\cite{article_15} & Multi-class Clinical Classification & Real-world clinical datasets with significant class imbalance from multiple hospital trusts & Feature selection, normalization, preparation for sequential decision-making & Combined dueling and double deep Q-learning for imbalanced classification & Superior sensitivity for minority classes while maintaining high performance for majority classes; successful generalization across hospital trusts \\
\hline
\cite{article_16} & Sepsis and Acute Hypotension & Real-world datasets (sepsis and acute hypotension patients) & Integration of historical patient observations, standard preprocessing (cleaning, normalization), offline dataset preparation & Transformer-based Deep Attention Q-Network, considering past observations for treatment recommendations & Outperformed LSTM and standard RL baselines in off-policy evaluation; better expected rewards than clinician policies \\
\hline
\cite{article_17} & Oropharyngeal squamous cell carcinoma & 536 patient records (MD Anderson, 2005–2013), with radiomics features & Random split (75\% train, 25\% test); radiomics used in select training runs & Deep Q-Learning on 3-step MDP; state: patient condition, action: treatment step, reward: survival + toxicity & Achieved 87.35\% mean accuracy; improved predicted survival by 3.73\% and reduced dysphagia by 0.75\% \\
\hline
\cite{article_18} & Type 2 diabetes with multimorbidity & 16,665 EHRs from NYU Langone (2009–2017) & 60\% train, 40\% test; excluded non-longitudinal or emergency visits & RL models for glycemia, BP, and CVD; actions: treatments; states: labs, history; rewards: target outcomes & High concordance with clinicians; better outcomes in disagreement cases (86.1\% for glycemia, 98.4\% for CVD) \\
\hline
\cite{article_19} & Cancer therapy personalization & 1080 RNA-seq patients, 223 drugs, TCGA + GDSC & Filtered samples by PubChem ID, harmonized gene expression data & PPORank (DRL), actor-critic with PPO; ranks treatments by optimizing NDCG & Outperformed SOTA supervised methods; sample-efficient and stable under high-dimensional data \\
\hline
\cite{article_20} & COVID-19 diagnosis using CT images & 1,065 CT images (including COVID-19, viral pneumonia, and false negatives) & ROI extraction, resized to 299x299, RGB conversion for model input & Modified Inception model (M-inception), fine-tuned with transfer learning & 89.5\% accuracy on internal validation; 85.2\% on difficult false-negative cases \\
\hline
\cite{article_21} & Macular degeneration, diabetic retinopathy, pneumonia & OCT images (108,312) + Chest X-rays (5,232 + 624 test) & Quality filtering of OCT images, categorization by diagnosis & Transfer learning with pre-trained CNN for medical image classification & 96.6\% accuracy (OCT), 92.8\% accuracy (pneumonia X-rays) \\
\hline
\end{tabular}
\caption{Comparison of AI Approaches in Health Applications}
\label{tab:ai_health_comparison}
\end{adjustwidth}
\end{table}
% \newpage
% \section{Discussion}
% As presented in the table above, different methods were proposed using machine learning which are seen as the most effective technique to build an intrusion detection system and detect attacks with different datasets mostly NSL-KDD dataset which resulted in a good accuracy.\\
% Nearly half of the studies did not work with normalization, there are also studies that did not perform a feature selection, as well as the most did not test many learning algorithms and the most of studies work on binary classification (normal or attack).


% \section{Conclusion}
% In this chapter, we studied and evaluated the latest methods proposed by recent research, about the use of machine learning methods for attacks classification based on data-sets.

% Most of the studied architectures could more or less achieve satisfying results with high accuracy. However, further research using large and fresh data-sets is always required to improve the performance of the existing methods for more efficient results.



